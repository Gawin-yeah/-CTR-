import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from openai import OpenAI
import io
from docx import Document
from docx.shared import Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
from openpyxl import load_workbook

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="CTR äº¤äº’é‡æ„ç³»ç»Ÿ (V48)", layout="wide")
st.title("ğŸ¯ é¦–é¡µå¡ç‰‡ CTR äº¤äº’é‡æ„ç³»ç»Ÿ (V48.0)")

# ==========================================
# ğŸ§  0. çŠ¶æ€è®°å¿†
# ==========================================
if 'persist_ex_a' not in st.session_state: st.session_state.persist_ex_a = []
if 'persist_ex_b' not in st.session_state: st.session_state.persist_ex_b = []
if 'persist_ex_dual' not in st.session_state: st.session_state.persist_ex_dual = []
if 'persist_in_a' not in st.session_state: st.session_state.persist_in_a = []
if 'persist_in_b' not in st.session_state: st.session_state.persist_in_b = []
if 'persist_in_dual' not in st.session_state: st.session_state.persist_in_dual = []

def update_ex_a(): st.session_state.persist_ex_a = st.session_state.k_ex_a
def update_ex_b(): st.session_state.persist_ex_b = st.session_state.k_ex_b
def update_ex_dual(): st.session_state.persist_ex_dual = st.session_state.k_ex_dual
def update_in_a(): st.session_state.persist_in_a = st.session_state.k_in_a
def update_in_b(): st.session_state.persist_in_b = st.session_state.k_in_b
def update_in_dual(): st.session_state.persist_in_dual = st.session_state.k_in_dual

# ==========================================
# ğŸ› ï¸ ç»˜å›¾ä¸å·¥å…·å‡½æ•°
# ==========================================
def plot_dual_axis(df, x_col, bar_col, line_col, title):
    fig = go.Figure()
    fig.add_trace(go.Bar(x=df[x_col], y=df[bar_col], name="æ€»æ›å…‰", marker_color='#A9CCE3', opacity=0.6, yaxis='y1'))
    fig.add_trace(go.Scatter(x=df[x_col], y=df[line_col], name="CTR", mode='lines+markers', line=dict(color='#E74C3C', width=3), marker=dict(size=8), yaxis='y2'))
    fig.update_layout(title=title, xaxis_title="æ—¥æœŸ", yaxis=dict(title="æ›å…‰", side="left", showgrid=False), yaxis2=dict(title="CTR", side="right", overlaying="y", tickformat=".2%", showgrid=True), hovermode="x unified", legend=dict(orientation="h", y=1.1), template="plotly_white", height=400)
    return fig

def plot_bar_race(df, x_col, y_col, title):
    df[y_col] = df[y_col].astype(str)
    fig = px.bar(df, x=x_col, y=y_col, orientation='h', title=title, text_auto='.2%', color=x_col, color_continuous_scale='Blues')
    fig.update_layout(yaxis={'categoryorder':'total ascending', 'type': 'category'}, template="plotly_white", height=350, showlegend=False)
    return fig

def plot_pie(df, names, values, title):
    fig = px.pie(df, names=names, values=values, title=title, hole=0.4)
    fig.update_layout(template="plotly_white", height=350)
    return fig

def plot_paired_bar(df, category_col, val_a, val_b, title):
    df[category_col] = df[category_col].astype(str)
    df_melt = df.melt(id_vars=[category_col], value_vars=[val_a, val_b], var_name='æ—¶æœŸ', value_name='CTR')
    df_melt['æ—¶æœŸ'] = df_melt['æ—¶æœŸ'].map({val_a: 'æ—¶æœŸA', val_b: 'æ—¶æœŸB'})
    fig = px.bar(df_melt, y=category_col, x='CTR', color='æ—¶æœŸ', barmode='group', orientation='h', text_auto='.2%', title=title)
    fig.update_layout(yaxis={'categoryorder':'total ascending', 'type': 'category'}, xaxis_tickformat=".2%", height=500, legend=dict(orientation="h", y=1.1))
    return fig

def plot_impact_diverging(df, category_col, impact_col, title):
    df[category_col] = df[category_col].astype(str)
    df['Color'] = df[impact_col].apply(lambda x: '#E74C3C' if x >= 0 else '#2ECC71')
    fig = go.Figure(go.Bar(y=df[category_col], x=df[impact_col], orientation='h', marker=dict(color=df['Color']), text=df[impact_col], texttemplate='%{text:+.2%}', textposition='outside'))
    fig.update_layout(title=title, yaxis={'categoryorder':'total ascending', 'type': 'category'}, xaxis_tickformat=".2%", height=500)
    return fig

def generate_excel(dfs_dict):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        for sheet_name, df in dfs_dict.items():
            safe_name = sheet_name[:30]
            df.to_excel(writer, sheet_name=safe_name, index=False)
    return output.getvalue()

def generate_word_report(title, metrics, summary_text, tables_data):
    doc = Document()
    doc.add_heading(title, 0).alignment = WD_ALIGN_PARAGRAPH.CENTER
    doc.add_paragraph(f"ç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}")
    doc.add_heading('ä¸€ã€æ ¸å¿ƒå¤§ç›˜æˆ˜æŠ¥', level=1)
    p = doc.add_paragraph()
    for k, v in metrics.items(): p.add_run(f"{k}: {v}\n").bold = True
    doc.add_heading('äºŒã€æ·±åº¦å½’å› ä¸æ´å¯Ÿ', level=1)
    doc.add_paragraph(summary_text)
    for t_title, df in tables_data.items():
        if df.empty: continue
        doc.add_heading(f"ä¸‰ã€{t_title}", level=1)
        t = doc.add_table(rows=1, cols=len(df.columns))
        t.style = 'Table Grid'
        for i, c in enumerate(df.columns): t.rows[0].cells[i].text = str(c)
        for _, r in df.iterrows():
            row = t.add_row()
            for i, v in enumerate(r):
                row.cells[i].text = f"{v:.2%}" if isinstance(v, float) and abs(v)<1 else str(v)
    output = io.BytesIO()
    doc.save(output)
    return output.getvalue()

# ==========================================
# ğŸ¤– AI åŠ©æ‰‹
# ==========================================
def init_ai_sidebar(context_data):
    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ¤– AI æ™ºèƒ½åˆ†æåŠ©æ‰‹")
    with st.sidebar.expander("âš™ï¸ æ¨¡å‹é…ç½®", expanded=False):
        api_key = st.text_input("API Key", type="password")
        base_url = st.text_input("Base URL", value="https://api.deepseek.com")
        model_name = st.text_input("Model Name", value="deepseek-chat")
    
    if "messages" not in st.session_state: st.session_state.messages = []
    for msg in st.session_state.messages:
        with st.sidebar.chat_message(msg["role"]): st.markdown(msg["content"])
    
    if prompt := st.sidebar.chat_input("é—®æˆ‘..."):
        if not api_key: st.sidebar.error("è¯·å¡«å…¥ API Key")
        else:
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.sidebar.chat_message("user"): st.markdown(prompt)
            with st.sidebar.chat_message("assistant"):
                msg_ph = st.empty()
                full_res = ""
                try:
                    client = OpenAI(api_key=api_key, base_url=base_url)
                    stream = client.chat.completions.create(
                        model=model_name,
                        messages=[{"role": "system", "content": f"åŸºäºæ•°æ®å›ç­”ï¼š\n{context_data}"}] + [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
                        stream=True,
                    )
                    for chunk in stream:
                        if chunk.choices[0].delta.content:
                            full_res += chunk.choices[0].delta.content
                            msg_ph.markdown(full_res + "â–Œ")
                    msg_ph.markdown(full_res)
                    st.session_state.messages.append({"role": "assistant", "content": full_res})
                except Exception as e: st.error(str(e))

GLOBAL_DATA_CONTEXT = "æš‚æ— æ•°æ®ã€‚"

# ==========================================
# ğŸ“‚ æ•°æ®æ¥å…¥
# ==========================================
st.sidebar.header("1. æ•°æ®æ¥å…¥")
manual_country = st.sidebar.text_input("âœï¸ æ‰€å±å›½å®¶", value="US").upper()
read_visible_only = st.sidebar.checkbox("ğŸ‘ï¸ åªè¯»å–æ˜¾ç¤ºè¡Œ (å‰”é™¤ç­›é€‰éšè—)", value=False)

file_a = st.sidebar.file_uploader("ä¸Šä¼ ä¸»è¡¨æ ¼ (A)", type=["xlsx", "xls"], key="file_a")
sheet_name_a = 0
if file_a:
    try:
        xls = pd.ExcelFile(file_a)
        if len(xls.sheet_names) > 1: sheet_name_a = st.sidebar.selectbox(f"è¡¨Aå·¥ä½œè¡¨:", xls.sheet_names, key="s_a")
    except: pass

file_b = st.sidebar.file_uploader("ä¸Šä¼ å¯¹æ¯”è¡¨æ ¼ (B)", type=["xlsx", "xls"], key="file_b")
sheet_name_b = 0
if file_b:
    try:
        xls = pd.ExcelFile(file_b)
        if len(xls.sheet_names) > 1: sheet_name_b = st.sidebar.selectbox(f"è¡¨Bå·¥ä½œè¡¨:", xls.sheet_names, key="s_b")
    except: pass

st.sidebar.markdown("---")
min_exp_noise = st.sidebar.number_input("ğŸ“‰ å•æ—¥æœ€å°æ›å…‰é˜ˆå€¼ (å»å™ª)", value=50, step=50)

def extract_start_date(s):
    s = str(s).strip()
    if "~" in s: return s.split("~")[0].strip()
    if "ï½" in s: return s.split("ï½")[0].strip()
    return s

@st.cache_data
def process_data(file, sheet_name=0, visible_only=False, min_exp=50):
    try:
        if visible_only:
            wb = load_workbook(file, data_only=True, read_only=False)
            ws = wb.active if sheet_name == 0 else wb[sheet_name]
            data = []
            rows = ws.iter_rows(values_only=False)
            headers = None
            for row in rows:
                if ws.row_dimensions[row[0].row].hidden: continue
                vals = [c.value for c in row]
                if headers is None: headers = vals
                else: data.append(vals)
            raw_df = pd.DataFrame(data, columns=headers)
        else:
            raw_df = pd.read_excel(file, sheet_name=sheet_name)
            
        rename_map = {}
        for col in raw_df.columns:
            if "å¡ç‰‡" in col or "Card" in col: rename_map[col] = 'card_id'
            elif "å‘ä½" in col or "Slot" in col: rename_map[col] = 'slot_id'
            elif "æŒ‡æ ‡" in col: rename_map[col] = 'metric_name'
        df = raw_df.rename(columns=rename_map)
        
        if 'slot_id' not in df.columns: df['slot_id'] = 'Default'
        df['card_id'] = df['card_id'].astype(str)
        df['slot_id'] = df['slot_id'].astype(str)
        
        fixed = ['card_id', 'slot_id', 'metric_name', 'åˆè®¡', 'å‡å€¼', 'æ€»è®¡', 'Total']
        dates = [c for c in df.columns if c not in fixed and "Unnamed" not in str(c)]
        
        melted = df.melt(id_vars=['card_id', 'slot_id', 'metric_name'], value_vars=dates, var_name='raw_date', value_name='count')
        melted['date'] = pd.to_datetime(melted['raw_date'].apply(extract_start_date), errors='coerce').dt.date
        melted = melted.dropna(subset=['date'])
        melted['count'] = pd.to_numeric(melted['count'], errors='coerce').fillna(0)
        
        def get_type(t):
            if "æ›å…‰" in str(t): return "exposure_uv"
            if "ç‚¹å‡»" in str(t): return "click_uv"
            return None
        melted['type'] = melted['metric_name'].apply(get_type)
        melted = melted.dropna(subset=['type'])
        
        final = melted.pivot_table(index=['date', 'card_id', 'slot_id'], columns='type', values='count', aggfunc='sum').reset_index()
        for c in ['exposure_uv', 'click_uv']:
            if c not in final.columns: final[c] = 0
            
        final = final[(final['exposure_uv']>=min_exp) & (final['click_uv']<=final['exposure_uv'])]
        return final
    except: return None

# --- V47 å…¨å±€æ¸…æ´—å‡½æ•° ---
def filter_dataframe(df, min_exp):
    if df is None: return None
    return df[(df['exposure_uv'] >= min_exp) & (df['click_uv'] <= df['exposure_uv'])].copy()

# --- 4. å•æ–‡ä»¶è§†å›¾ (V48 é‡æ„ï¼šæœç´¢ & å¤šç»´åº¦) ---
def render_analysis_view(data, group_cols, view_name, unique_key_prefix):
    period = data.groupby(group_cols).agg({'exposure_uv':'sum', 'click_uv':'sum'}).reset_index()
    period['åŠ æƒCTR'] = period['click_uv']/period['exposure_uv']
    
    daily = data.groupby(group_cols + ['date']).agg({'exposure_uv':'sum', 'click_uv':'sum'}).reset_index()
    daily['daily_ctr'] = daily['click_uv']/daily['exposure_uv']
    
    arith = daily.groupby(group_cols)['daily_ctr'].mean().reset_index().rename(columns={'daily_ctr':'ç®—æœ¯CTR'})
    
    merged = pd.merge(period, arith, on=group_cols, how='left').sort_values('exposure_uv', ascending=False)
    
    display = merged.copy()
    if 'slot_id' in group_cols: display['label'] = display['card_id'] + " (" + display['slot_id'] + ")"
    else: display['label'] = display['card_id']
    
    # Dashboard
    with st.expander(f"ğŸ“Š {view_name} - Leader é©¾é©¶èˆ±", expanded=True):
        c1, c2 = st.columns(2)
        with c1: st.plotly_chart(plot_pie(display.head(8), 'label', 'exposure_uv', "æµé‡ Top 8"), use_container_width=True)
        with c2: 
            top_ctr = display[display['exposure_uv'] > display['exposure_uv'].mean()*0.1].head(10)
            if not top_ctr.empty:
                st.plotly_chart(plot_bar_race(top_ctr, 'åŠ æƒCTR', 'label', "é«˜æ½œ Top 10"), use_container_width=True)
            else:
                st.info("æ•°æ®ä¸è¶³ä»¥æ’å")

    # === V48 äº¤äº’å‡çº§ï¼šå¤§å±æœç´¢ä¸ç»´åº¦åˆ‡æ¢ ===
    st.markdown("---")
    st.markdown(f"#### ğŸ“‹ è¯¦ç»†æ•°æ®é€è§† ({view_name})")
    
    c_s1, c_s2 = st.columns([2, 1])
    with c_s1:
        # 1. æ˜¾çœ¼çš„å¤šé€‰æœç´¢æ¡†
        search_vals = st.multiselect(f"ğŸ” æœç´¢/ç­›é€‰å¡ç‰‡ (æ”¯æŒå¤šé€‰)", display['label'].unique(), key=f"search_{unique_key_prefix}")
    with c_s2:
        # 2. è¡¨æ ¼å±•ç¤ºç»´åº¦åˆ‡æ¢
        table_metric = st.radio("ğŸ“Š è¡¨æ ¼å±•ç¤ºæ¯æ—¥æŒ‡æ ‡:", ["æ¯æ—¥ CTR", "æ¯æ—¥ æ›å…‰", "æ¯æ—¥ ç‚¹å‡»"], horizontal=True, key=f"tm_{unique_key_prefix}")
    
    # åŠ¨æ€è®¡ç®— Pivot æ•°æ®
    if table_metric == "æ¯æ—¥ CTR":
        val_col = 'daily_ctr'
        fmt_str = '{:.2%}'
    elif table_metric == "æ¯æ—¥ æ›å…‰":
        val_col = 'exposure_uv'
        fmt_str = '{:,.0f}'
    else:
        val_col = 'click_uv'
        fmt_str = '{:,.0f}'
        
    pivot = daily.pivot_table(index=group_cols, columns='date', values=val_col, aggfunc='sum' if val_col != 'daily_ctr' else 'mean')
    pivot.columns = [d.strftime('%m-%d') for d in pivot.columns]
    
    # åˆå¹¶ Pivot
    final_display = pd.merge(display, pivot, on=group_cols, how='left')
    
    # åº”ç”¨æœç´¢
    if search_vals:
        final_display = final_display[final_display['label'].isin(search_vals)]
    
    cols = ['card_id', 'slot_id', 'åŠ æƒCTR', 'ç®—æœ¯CTR', 'exposure_uv', 'click_uv'] if 'slot_id' in group_cols else ['card_id', 'åŠ æƒCTR', 'ç®—æœ¯CTR', 'exposure_uv', 'click_uv']
    cols += [c for c in pivot.columns]
    
    # æ¸²æŸ“è¡¨æ ¼
    fmt = {'åŠ æƒCTR':'{:.2%}', 'ç®—æœ¯CTR':'{:.2%}', 'exposure_uv':'{:.0f}', 'click_uv':'{:.0f}'}
    for c in pivot.columns: fmt[c] = fmt_str
    
    st.dataframe(
        final_display[cols].style.format(fmt).background_gradient(subset=['åŠ æƒCTR'], cmap='RdYlGn', axis=0), 
        use_container_width=True, 
        height=500
    )

    # === V48 è¶‹åŠ¿ä¸‹é’»ï¼šå¢åŠ ç‚¹å‡»é‡ ===
    st.markdown("#### ğŸ“ˆ è¶‹åŠ¿ä¸‹é’»")
    # å¦‚æœä¸Šé¢æœç´¢äº†ï¼Œä¸‹é¢é»˜è®¤é€‰ä¸­æœç´¢çš„å†…å®¹
    default_trend = search_vals if search_vals else []
    sel = st.multiselect(f"é€‰æ‹©å¯¹è±¡ç”»å›¾", display['label'].unique(), default=default_trend, key=f"ms_{unique_key_prefix}")
    
    if sel:
        metric_choice = st.radio("è¶‹åŠ¿æŒ‡æ ‡:", ["âœ¨ CTR", "ğŸ“Š æ›å…‰é‡", "ğŸ‘† ç‚¹å‡»é‡"], horizontal=True, key=f"rd_{unique_key_prefix}")
        plot_df = daily.copy()
        if 'slot_id' in group_cols: plot_df['label'] = plot_df['card_id'] + " (" + plot_df['slot_id'] + ")"
        else: plot_df['label'] = plot_df['card_id']
        plot_df = plot_df[plot_df['label'].isin(sel)]
        
        if metric_choice == "CTR":
            y_col, fmt_p = 'daily_ctr', ".2%"
        elif metric_choice == "æ›å…‰é‡":
            y_col, fmt_p = 'exposure_uv', ".0f"
        else:
            y_col, fmt_p = 'click_uv', ".0f"
            
        st.plotly_chart(px.line(plot_df, x='date', y=y_col, color='label', markers=True, title=f"æ¯æ—¥ {metric_choice} èµ°åŠ¿").update_yaxes(tickformat=fmt_p), use_container_width=True)

def show_single_analysis(df, label="è¡¨æ ¼ A", is_secondary=False):
    # (è®°å¿†é€»è¾‘ä¿æŒ V47 ä¸å˜)
    if label == "è¡¨æ ¼ A":
        key_ex, key_in = "k_ex_a", "k_in_a"
        def_ex, def_in = st.session_state.persist_ex_a, st.session_state.persist_in_a
        cb_ex, cb_in = update_ex_a, update_in_a
    elif label == "è¡¨æ ¼ B":
        key_ex, key_in = "k_ex_b", "k_in_b"
        def_ex, def_in = st.session_state.persist_ex_b, st.session_state.persist_in_b
        cb_ex, cb_in = update_ex_b, update_in_b
    else: 
        key_ex, key_in = f"ex_{label}", f"in_{label}"
        def_ex, def_in = [], []
        cb_ex, cb_in = None, None

    st.markdown(f"## ğŸ” {label} - æ·±åº¦åˆ†æ")
    
    if not is_secondary:
        if st.checkbox("âš”ï¸ å¼€å¯è¡¨å†…å¯¹æ¯”", key=f"sw_{label}"):
            show_comparison_logic(df, df, f"{label}-A", f"{label}-B")
            return

    all_cards = sorted(df['card_id'].unique())
    valid_def_in = [x for x in def_in if x in all_cards]
    valid_def_ex = [x for x in def_ex if x in all_cards]

    col_f1, col_f2 = st.columns(2)
    with col_f1:
        include_list = st.multiselect("âœ… åªçœ‹æŒ‡å®šå¡ç‰‡", all_cards, default=valid_def_in, key=key_in, on_change=cb_in)
    with col_f2:
        exclude_list = st.multiselect("ğŸš« å‰”é™¤æŒ‡å®šå¡ç‰‡", all_cards, default=valid_def_ex, key=key_ex, on_change=cb_ex)
    
    sub_df_raw = df.copy()
    if include_list: sub_df_raw = sub_df_raw[sub_df_raw['card_id'].isin(include_list)]
    if exclude_list: sub_df_raw = sub_df_raw[~sub_df_raw['card_id'].isin(exclude_list)]
    
    min_d, max_d = sub_df_raw['date'].min(), sub_df_raw['date'].max()
    dr = st.date_input("é€‰æ‹©å‘¨æœŸ", [min_d, max_d], key=f"dr_{label}")
    if len(dr) != 2: return
    
    sub = sub_df_raw[(sub_df_raw['date']>=dr[0]) & (sub_df_raw['date']<=dr[1])].copy()
    
    e_tot = sub['exposure_uv'].sum()
    c_tot = sub['click_uv'].sum()
    ctr_w = c_tot/e_tot if e_tot>0 else 0
    daily_g = sub.groupby('date').agg({'exposure_uv':'sum', 'click_uv':'sum'}).reset_index()
    daily_g['ctr'] = daily_g['click_uv']/daily_g['exposure_uv']
    
    st.markdown("### ğŸŒ å…¨ç›˜è¶‹åŠ¿é©¾é©¶èˆ±")
    st.plotly_chart(plot_dual_axis(daily_g, 'date', 'exposure_uv', 'ctr', "å…¨ç›˜æµé‡ vs æ•ˆç‡"), use_container_width=True)
    
    c1, c2, c3 = st.columns(3)
    c1.metric("æ€»æ›å…‰", f"{e_tot:,.0f}")
    c2.metric("æ€»ç‚¹å‡»", f"{c_tot:,.0f}")
    c3.metric("åŠ æƒå‡å€¼ CTR", f"{ctr_w:.2%}")
    
    if not is_secondary:
        global GLOBAL_DATA_CONTEXT
        GLOBAL_DATA_CONTEXT = f"å•è¡¨:{label}, å‰”é™¤:{exclude_list}, CTR:{ctr_w:.2%}, æ›å…‰:{e_tot}"
    
    st.divider()
    t1, t2 = st.tabs(["ğŸ’³ è§†å›¾:åªçœ‹å¡ç‰‡", "ğŸ“ è§†å›¾:ç»†åˆ†å‘ä½"])
    with t1: render_analysis_view(sub, ['card_id'], "å¡ç‰‡ç»´åº¦", label+"1")
    with t2: render_analysis_view(sub, ['card_id', 'slot_id'], "å‘ä½ç»´åº¦", label+"2")
    
    st.divider()
    st.header("ğŸ“¥ å¯¼å‡ºä¸­å¿ƒ")
    c_e1, c_e2 = st.columns(2)
    export_df = sub.groupby(['card_id', 'slot_id']).agg({'exposure_uv':'sum', 'click_uv':'sum'}).reset_index()
    export_df['weighted_ctr'] = export_df['click_uv'] / export_df['exposure_uv']
    export_df = export_df.sort_values('exposure_uv', ascending=False)
    top_5 = export_df.head(5).rename(columns={'card_id':'å¡ç‰‡ID', 'weighted_ctr':'CTR', 'exposure_uv':'æ›å…‰'})
    
    word_file = generate_word_report(f"æŠ¥å‘Š-{manual_country}", {"å‘¨æœŸ": str(dr), "æ›å…‰": f"{e_tot:,.0f}", "CTR": f"{ctr_w:.2%}"}, "æ•°æ®è¯¦è§é™„è¡¨", {"Top5": top_5})
    excel_file = generate_excel({"èšåˆ": export_df, "æ˜ç»†": sub})
    with c_e1: st.download_button("ğŸ“„ Word æŠ¥å‘Š", word_file, f"Report_{label}.docx", key=f"bw_{label}")
    with c_e2: st.download_button("ğŸ“Š Excel æ•°æ®", excel_file, f"Data_{label}.xlsx", key=f"be_{label}")

# --- 5. åŒè¡¨å¯¹æ¯” (ä¿æŒV47é€»è¾‘) ---
def show_comparison_logic(d1_raw, d2_raw, la="A", lb="B"):
    st.markdown("### âš™ï¸ å¯¹æ¯”é…ç½®")
    mode = st.radio("ç»´åº¦", ["ğŸ’³ ä»…å¡ç‰‡", "ğŸ“ å¡ç‰‡+å‘ä½"], horizontal=True, key=f"rd_{la}")
    cols = ['card_id'] if "ä»…" in mode else ['card_id', 'slot_id']
    
    all_cards = sorted(list(set(d1_raw['card_id'])|set(d2_raw['card_id'])))
    
    if la == "è¡¨æ ¼A": 
        key_ex, key_in = "k_ex_dual", "k_in_dual"
        def_ex, def_in = st.session_state.persist_ex_dual, st.session_state.persist_in_dual
        cb_ex, cb_in = update_ex_dual, update_in_dual
    else: 
        key_ex, key_in = f"ex_{la}", f"in_{la}"
        def_ex, def_in = [], []
        cb_ex, cb_in = None, None

    valid_def_in = [x for x in def_in if x in all_cards]
    valid_def_ex = [x for x in def_ex if x in all_cards]

    col_f1, col_f2 = st.columns(2)
    with col_f1:
        inc = st.multiselect("âœ… åªçœ‹æŒ‡å®šå¡ç‰‡", all_cards, default=valid_def_in, key=key_in, on_change=cb_in)
    with col_f2:
        excl = st.multiselect("ğŸš« å‰”é™¤æŒ‡å®šå¡ç‰‡", all_cards, default=valid_def_ex, key=key_ex, on_change=cb_ex)
    
    d1, d2 = d1_raw.copy(), d2_raw.copy()
    if inc:
        d1 = d1[d1['card_id'].isin(inc)]
        d2 = d2[d2['card_id'].isin(inc)]
    if excl:
        d1 = d1[~d1['card_id'].isin(excl)]
        d2 = d2[~d2['card_id'].isin(excl)]
    
    c1, c2 = st.columns(2)
    dr1 = c1.date_input(f"{la} æ—¶é—´", [d1['date'].min(), d1['date'].max()], key=f"d1_{la}")
    dr2 = c2.date_input(f"{lb} æ—¶é—´", [d2['date'].min(), d2['date'].max()], key=f"d2_{la}")
    
    if len(dr1)==2 and len(dr2)==2:
        d1f = d1[(d1['date']>=dr1[0])&(d1['date']<=dr1[1])]
        d2f = d2[(d2['date']>=dr2[0])&(d2['date']<=dr2[1])]
        
        def get_g(d):
            e=d['exposure_uv'].sum(); c=d['click_uv'].sum()
            return e,c,c/e if e>0 else 0
        
        ea, ca, ctra = get_g(d1f)
        eb, cb, ctrb = get_g(d2f)
        
        top = d2f.groupby('card_id')['click_uv'].sum().sort_values(ascending=False).head(1)
        res_txt, top_info = "", "æ— "
        if not top.empty:
            tid = top.index[0]
            d1n, d2n = d1f[d1f['card_id']!=tid], d2f[d2f['card_id']!=tid]
            _,_,can = get_g(d1n)
            _,_,cbn = get_g(d2n)
            mult = cbn/can if can>0 else 0
            conc = "âœ… æ™®æ¶¨" if mult>1.05 else "âš ï¸ å¤´éƒ¨ä¾èµ–"
            res_txt = f"å‰”é™¤Top1ã€{tid}ã€‘åå€æ•°: {mult:.2f}ã€‚ç»“è®º: {conc}"
            top_info = f"{tid}"
            st.info(f"ğŸ“ æ·±åº¦å½’å› ï¼š{res_txt}")

        st.subheader("ğŸ“Š å…¨ç›˜æˆ˜æŠ¥")
        k1, k2, k3, k4 = st.columns(4)
        k1.metric("CTR", f"{ctrb:.2%}", f"{ctrb-ctra:.2%}")
        k2.metric("æ›å…‰", f"{eb:,.0f}", f"{(eb-ea)/ea if ea else 0:.1%}")
        k3.metric("ç‚¹å‡»", f"{cb:,.0f}", f"{(cb-ca)/ca if ca else 0:.1%}")
        
        diag = "å¸¸è§„"
        if (eb-ea)/ea < -0.2 and (cb-ca)/ca < -0.1: diag = "âš ï¸ è™šå‡ææ•ˆ"
        elif (eb-ea)/ea > 0.2 and (ctrb-ctra) < 0: diag = "ğŸŸ  æµé‡ç¨€é‡Š"
        elif (ctrb/ctra if ctra else 0) > 1.05 and (cb-ca)/ca > 0: diag = "ğŸŸ¢ æœ‰æ•ˆå¢é•¿"
        k4.info(diag)
        
        global GLOBAL_DATA_CONTEXT
        GLOBAL_DATA_CONTEXT = f"å¯¹æ¯”: CTR {ctra:.2%}->{ctrb:.2%}, è¯Šæ–­:{diag}, å½’å› :{res_txt}"

        s1 = d1f.groupby(cols).agg({'exposure_uv':'sum', 'click_uv':'sum'}).reset_index()
        s2 = d2f.groupby(cols).agg({'exposure_uv':'sum', 'click_uv':'sum'}).reset_index()
        s1 = s1.rename(columns={'exposure_uv':'Exp_A', 'click_uv':'Clk_A'})
        s2 = s2.rename(columns={'exposure_uv':'Exp_B', 'click_uv':'Clk_B'})
        s1['CTR_A'] = s1['Clk_A']/s1['Exp_A']
        s2['CTR_B'] = s2['Clk_B']/s2['Exp_B']
        
        comp = pd.merge(s1, s2, on=cols, how='outer', indicator=True)
        comp['_merge'] = comp['_merge'].astype(str).fillna('both')
        comp['Diff'] = comp['CTR_B'].fillna(0) - comp['CTR_A'].fillna(0)
        
        def status(x):
            if x=='both': return 'å»¶ç»­'
            if x=='right_only': return 'æ–°ä¸Šæ¶'
            return 'ä¸‹æ¶'
        comp['Status'] = comp['_merge'].apply(status)
        
        st.subheader("ğŸ“ˆ Leader é©¾é©¶èˆ±")
        c_c1, c_c2 = st.columns(2)
        valid = comp[comp['Status']=='å»¶ç»­']
        
        if 'slot_id' in cols: valid['L'] = valid['card_id'] + " (" + valid['slot_id'] + ")"
        else: valid['L'] = valid['card_id']
        
        with c_c1:
            top10 = valid.sort_values('Exp_B', ascending=False).head(10)
            if not top10.empty:
                st.plotly_chart(plot_paired_bar(top10, 'L', 'CTR_A', 'CTR_B', "Top 10 æµé‡å¡ç‰‡ CTR å¯¹æ¯”"), use_container_width=True)
            
        with c_c2:
            top5 = valid.sort_values('Diff', ascending=False).head(5)
            bot5 = valid.sort_values('Diff', ascending=True).head(5)
            imp = pd.concat([top5, bot5])
            if not imp.empty:
                st.plotly_chart(plot_impact_diverging(imp, 'L', 'Diff', "æ¶¨è·Œå¹…çº¢é»‘æ¦œ"), use_container_width=True)

        st.dataframe(comp.style.format({'CTR_A':'{:.2%}', 'CTR_B':'{:.2%}', 'Diff':'{:.2%}'}).background_gradient(subset=['Diff'], cmap='RdYlGn', vmin=-0.02, vmax=0.02), use_container_width=True)
        
        c_e1, c_e2 = st.columns(2)
        with c_e1: st.download_button("ğŸ“„ Word", generate_word_report(f"å¯¹æ¯”-{la}", {"CTR":f"{ctrb:.2%}"}, res_txt, {"æ¦œå•": imp[['L','Diff']]}), f"Rep_{la}.docx", key=f"bw_{la}")
        with c_e2: st.download_button("ğŸ“Š Excel", generate_excel({"Comp": comp}), f"Dat_{la}.xlsx", key=f"be_{la}")

def show_comparison(df1, df2):
    show_comparison_logic(df1, df2)

# --- ä¸»é€»è¾‘ ---
df_a_raw = None
if file_a: df_a_raw = process_data(file_a, sheet_name_a, visible_only=read_visible_only)
df_b_raw = None
if file_b: df_b_raw = process_data(file_b, sheet_name_b, visible_only=read_visible_only)

# å…¨å±€é˜ˆå€¼æ¸…æ´—
df_a = filter_dataframe(df_a_raw, global_min_exp)
df_b = filter_dataframe(df_b_raw, global_min_exp)

if df_a is not None:
    if df_b is not None:
        mode = st.radio("ğŸ‘‡ æ¨¡å¼", ["ğŸ“„ å•æ–‡ä»¶åˆ†æ", "âš”ï¸ åŒè¡¨å¯¹æ¯”"], horizontal=True)
        st.divider()
        if mode == "ğŸ“„ å•æ–‡ä»¶åˆ†æ":
            t1, t2 = st.tabs(["è¡¨æ ¼ A", "è¡¨æ ¼ B"])
            with t1: show_single_analysis(df_a, "è¡¨æ ¼ A")
            with t2: show_single_analysis(df_b, "è¡¨æ ¼ B", is_secondary=True)
        else:
            show_comparison(df_a, df_b)
    else:
        show_single_analysis(df_a, "è¡¨æ ¼ A")
else:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¸Šä¼  Excel æ–‡ä»¶ã€‚")

if GLOBAL_DATA_CONTEXT != "æš‚æ— æ•°æ®ã€‚":
    init_ai_sidebar(GLOBAL_DATA_CONTEXT)
