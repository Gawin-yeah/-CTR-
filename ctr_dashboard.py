import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from openai import OpenAI
import io
from docx import Document
from docx.shared import Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
from openpyxl import load_workbook

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="CTR è§†è§‰é‡æ„ç³»ç»Ÿ (V37)", layout="wide")
st.title("ğŸ¯ é¦–é¡µå¡ç‰‡ CTR è§†è§‰é‡æ„ç³»ç»Ÿ (V37.0 Leaderçœ‹æ¿)")

# ==========================================
# ğŸ› ï¸ ç»˜å›¾å‡½æ•°é›† (V37 é‡æ„)
# ==========================================
def plot_paired_bar(df, category_col, val_a, val_b, title):
    """ç»˜åˆ¶ A/B æ—¶æœŸå¯¹æ¯”æŸ±çŠ¶å›¾ (åˆ†ç»„)"""
    # è½¬æ¢æ•°æ®æ ¼å¼ä¸ºé•¿è¡¨ï¼Œæ–¹ä¾¿ Plotly åˆ†ç»„
    df_melt = df.melt(id_vars=[category_col], value_vars=[val_a, val_b], 
                      var_name='æ—¶æœŸ', value_name='CTR')
    
    # æ˜ å°„å‹å¥½çš„åå­—
    df_melt['æ—¶æœŸ'] = df_melt['æ—¶æœŸ'].map({val_a: 'æ—¶æœŸ A (åŸºå‡†)', val_b: 'æ—¶æœŸ B (å½“å‰)'})
    
    fig = px.bar(df_melt, y=category_col, x='CTR', color='æ—¶æœŸ', barmode='group',
                 title=title, orientation='h', text_auto='.2%',
                 color_discrete_map={'æ—¶æœŸ A (åŸºå‡†)': '#95A5A6', 'æ—¶æœŸ B (å½“å‰)': '#3498DB'})
    
    fig.update_layout(
        yaxis={'categoryorder':'total ascending', 'type': 'category'}, # å¼ºåˆ¶åˆ†ç±»è½´
        xaxis_tickformat=".2%",
        legend=dict(orientation="h", y=1.1),
        height=500,
        margin=dict(l=20, r=20, t=50, b=20)
    )
    return fig

def plot_impact_diverging(df, category_col, impact_col, title):
    """ç»˜åˆ¶è´¡çŒ®åº¦/æ¶¨è·Œå¹… çº¢è‰²/ç»¿è‰²å›¾"""
    # æ ¹æ®æ­£è´Ÿå€¼ä¸Šè‰²
    df['Color'] = df[impact_col].apply(lambda x: '#E74C3C' if x >= 0 else '#2ECC71')
    
    fig = go.Figure()
    fig.add_trace(go.Bar(
        y=df[category_col],
        x=df[impact_col],
        orientation='h',
        marker=dict(color=df['Color']),
        text=df[impact_col],
        texttemplate='%{text:+.2%}',
        textposition='outside'
    ))
    
    fig.update_layout(
        title=title,
        yaxis={'categoryorder':'total ascending', 'type': 'category'},
        xaxis_tickformat=".2%",
        height=500,
        showlegend=False
    )
    return fig

# ... (ä¿ç•™åŸæœ‰çš„å¯¼å‡ºå‡½æ•°) ...
def generate_excel(dfs_dict):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        for sheet_name, df in dfs_dict.items():
            safe_sheet_name = sheet_name[:30]
            df.to_excel(writer, sheet_name=safe_sheet_name, index=False)
            worksheet = writer.sheets[safe_sheet_name]
            worksheet.set_column(0, len(df.columns) - 1, 15)
    return output.getvalue()

def generate_word_report(title, metrics, summary_text, tables_data):
    doc = Document()
    head = doc.add_heading(title, 0)
    head.alignment = WD_ALIGN_PARAGRAPH.CENTER
    doc.add_paragraph(f"ç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}")
    
    doc.add_heading('ä¸€ã€æ ¸å¿ƒå¤§ç›˜æˆ˜æŠ¥', level=1)
    p = doc.add_paragraph()
    for k, v in metrics.items():
        run = p.add_run(f"{k}: {v}\n")
        run.font.size = Pt(12)
        run.bold = True
    
    doc.add_heading('äºŒã€æ·±åº¦å½’å› ä¸æ´å¯Ÿ', level=1)
    doc.add_paragraph(summary_text)
    
    for table_title, df in tables_data.items():
        if df.empty: continue
        doc.add_heading(f"ä¸‰ã€{table_title}", level=1)
        t = doc.add_table(rows=1, cols=len(df.columns))
        t.style = 'Table Grid'
        hdr_cells = t.rows[0].cells
        for i, col_name in enumerate(df.columns): hdr_cells[i].text = str(col_name)
        for _, row in df.iterrows():
            row_cells = t.add_row().cells
            for i, val in enumerate(row):
                if isinstance(val, float): row_cells[i].text = f"{val:.2%}" if abs(val) < 1 else f"{val:,.0f}"
                else: row_cells[i].text = str(val)
    output = io.BytesIO()
    doc.save(output)
    return output.getvalue()

# ==========================================
# ğŸ¤– AI åŠ©æ‰‹
# ==========================================
def init_ai_sidebar(context_data):
    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ¤– AI æ™ºèƒ½åˆ†æåŠ©æ‰‹")
    with st.sidebar.expander("âš™ï¸ æ¨¡å‹é…ç½®", expanded=False):
        api_key = st.text_input("API Key", type="password")
        base_url = st.text_input("Base URL", value="https://api.deepseek.com")
        model_name = st.text_input("Model Name", value="deepseek-chat")
    
    if "messages" not in st.session_state: st.session_state.messages = []
    for message in st.session_state.messages:
        with st.sidebar.chat_message(message["role"]): st.markdown(message["content"])
    
    if prompt := st.sidebar.chat_input("é—®æˆ‘..."):
        if not api_key: st.sidebar.error("è¯·å¡«å…¥ API Key")
        else:
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.sidebar.chat_message("user"): st.markdown(prompt)
            with st.sidebar.chat_message("assistant"):
                msg_ph = st.empty()
                full_res = ""
                try:
                    client = OpenAI(api_key=api_key, base_url=base_url)
                    sys_prompt = f"ä½ æ˜¯ä¸€ä¸ªèµ„æ·±æ•°æ®åˆ†æå¸ˆã€‚åŸºäºä»¥ä¸‹æ•°æ®å›ç­”ï¼š\n{context_data}"
                    stream = client.chat.completions.create(
                        model=model_name,
                        messages=[{"role": "system", "content": sys_prompt}] + [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
                        stream=True,
                    )
                    for chunk in stream:
                        if chunk.choices[0].delta.content:
                            full_res += chunk.choices[0].delta.content
                            msg_ph.markdown(full_res + "â–Œ")
                    msg_ph.markdown(full_res)
                    st.session_state.messages.append({"role": "assistant", "content": full_res})
                except Exception as e: st.error(f"Error: {e}")

GLOBAL_DATA_CONTEXT = "æš‚æ— æ•°æ®ã€‚"

# ==========================================
# 1. æ•°æ®æ¥å…¥
# ==========================================
st.sidebar.header("1. æ•°æ®æ¥å…¥")
manual_country = st.sidebar.text_input("âœï¸ æ‰€å±å›½å®¶", value="US").upper()
read_visible_only = st.sidebar.checkbox("ğŸ‘ï¸ åªè¯»å–æ˜¾ç¤ºè¡Œ (å‰”é™¤ç­›é€‰éšè—)", value=False)

file_a = st.sidebar.file_uploader("ä¸Šä¼ ä¸»è¡¨æ ¼ (A)", type=["xlsx", "xls"], key="file_a")
sheet_name_a = 0
if file_a:
    try:
        xls = pd.ExcelFile(file_a)
        if len(xls.sheet_names) > 1: sheet_name_a = st.sidebar.selectbox(f"è¡¨Aå·¥ä½œè¡¨:", xls.sheet_names, key="s_a")
    except: pass

file_b = st.sidebar.file_uploader("ä¸Šä¼ å¯¹æ¯”è¡¨æ ¼ (B)", type=["xlsx", "xls"], key="file_b")
sheet_name_b = 0
if file_b:
    try:
        xls = pd.ExcelFile(file_b)
        if len(xls.sheet_names) > 1: sheet_name_b = st.sidebar.selectbox(f"è¡¨Bå·¥ä½œè¡¨:", xls.sheet_names, key="s_b")
    except: pass

st.sidebar.markdown("---")
min_exp_noise = st.sidebar.number_input("æœ€å°æ›å…‰é˜ˆå€¼", value=50, step=10)

def extract_start_date(header_str):
    s = str(header_str).strip()
    if "~" in s: return s.split("~")[0].strip()
    if "ï½" in s: return s.split("ï½")[0].strip()
    return s

@st.cache_data
def process_data(file, sheet_name=0, visible_only=False):
    try:
        if visible_only:
            wb = load_workbook(file, data_only=True, read_only=False)
            ws = wb.active if sheet_name == 0 else wb[sheet_name]
            data = []
            rows_iter = ws.iter_rows(values_only=False)
            headers = None
            for row in rows_iter:
                if ws.row_dimensions[row[0].row].hidden: continue
                row_values = [cell.value for cell in row]
                if headers is None: headers = row_values
                else: data.append(row_values)
            raw_df = pd.DataFrame(data, columns=headers)
        else:
            raw_df = pd.read_excel(file, sheet_name=sheet_name)
            
        rename_map = {}
        for col in raw_df.columns:
            if "å¡ç‰‡" in col or "Card" in col: rename_map[col] = 'card_id'
            elif "å‘ä½" in col or "Slot" in col: rename_map[col] = 'slot_id'
            elif "æŒ‡æ ‡" in col: rename_map[col] = 'metric_name'
        df = raw_df.rename(columns=rename_map)
        
        if 'slot_id' not in df.columns: df['slot_id'] = 'Default'
        df['card_id'] = df['card_id'].astype(str)
        df['slot_id'] = df['slot_id'].astype(str)
        
        fixed_cols = ['card_id', 'slot_id', 'metric_name', 'åˆè®¡', 'å‡å€¼', 'æ€»è®¡', 'Total']
        potential_date_cols = [c for c in df.columns if c not in fixed_cols and "Unnamed" not in str(c)]
        melted = df.melt(id_vars=['card_id', 'slot_id', 'metric_name'], value_vars=potential_date_cols, var_name='original_header', value_name='count')
        
        melted['date_str'] = melted['original_header'].apply(extract_start_date)
        melted['date'] = pd.to_datetime(melted['date_str'], errors='coerce').dt.date
        melted = melted.dropna(subset=['date'])
        melted['count'] = pd.to_numeric(melted['count'], errors='coerce').fillna(0)
        
        def get_type(t):
            if "æ›å…‰" in str(t): return "exposure_uv"
            if "ç‚¹å‡»" in str(t): return "click_uv"
            return None
        melted['type'] = melted['metric_name'].apply(get_type)
        melted = melted.dropna(subset=['type'])
        
        final_df = melted.pivot_table(index=['date', 'card_id', 'slot_id'], columns='type', values='count', aggfunc='sum').reset_index()
        for c in ['exposure_uv', 'click_uv']:
            if c not in final_df.columns: final_df[c] = 0
        final_df = final_df.fillna(0)
        final_df = final_df[final_df['exposure_uv'] >= min_exp_noise]
        final_df = final_df[final_df['click_uv'] <= final_df['exposure_uv']]
        return final_df
    except Exception as e: return None

# --- 3. å•æ–‡ä»¶åˆ†æ ---
def render_analysis_view(data, group_cols, view_name, unique_key_prefix):
    period_stats = data.groupby(group_cols).agg({'exposure_uv': 'sum', 'click_uv': 'sum'}).reset_index()
    period_stats['åŠ æƒå‡å€¼CTR'] = period_stats['click_uv'] / period_stats['exposure_uv']
    
    daily_agg = data.groupby(group_cols + ['date']).agg({'exposure_uv': 'sum', 'click_uv': 'sum'}).reset_index()
    daily_agg['daily_ctr'] = daily_agg['click_uv'] / daily_agg['exposure_uv']
    arithmetic_stats = daily_agg.groupby(group_cols)['daily_ctr'].mean().reset_index().rename(columns={'daily_ctr': 'ç®—æœ¯å‡å€¼CTR'})
    
    daily_pivot = daily_agg.pivot_table(index=group_cols, columns='date', values='daily_ctr', aggfunc='mean')
    daily_pivot.columns = [d.strftime('%m-%d') for d in daily_pivot.columns]
    
    merged = pd.merge(period_stats, arithmetic_stats, on=group_cols, how='left')
    merged = pd.merge(merged, daily_pivot, on=group_cols, how='left')
    merged = merged.sort_values('exposure_uv', ascending=False)
    
    display_df = merged.copy()
    if 'slot_id' in group_cols:
        display_df['label'] = display_df['card_id'] + " (å‘ä½ " + display_df['slot_id'] + ")"
    else:
        display_df['label'] = display_df['card_id']
    
    date_cols = [c for c in display_df.columns if '-' in c]
    final_cols = ['card_id', 'slot_id', 'åŠ æƒå‡å€¼CTR', 'ç®—æœ¯å‡å€¼CTR', 'exposure_uv', 'click_uv'] + date_cols
    # ç¡®ä¿åˆ—å­˜åœ¨
    final_cols = [c for c in final_cols if c in display_df.columns]
    
    show_df = display_df[final_cols].rename(columns={'card_id': 'å¡ç‰‡ID', 'slot_id': 'å‘ä½ID', 'exposure_uv': 'æ€»æ›å…‰', 'click_uv': 'æ€»ç‚¹å‡»'})

    st.markdown(f"#### ğŸ“‹ {view_name} - è¯¦ç»†æ•°æ®")
    format_dict = {'åŠ æƒå‡å€¼CTR': '{:.2%}', 'ç®—æœ¯å‡å€¼CTR': '{:.2%}', 'æ€»æ›å…‰': '{:,.0f}', 'æ€»ç‚¹å‡»': '{:,.0f}'}
    for d in date_cols: format_dict[d] = '{:.2%}'
    styled_df = show_df.style.format(format_dict).background_gradient(subset=['åŠ æƒå‡å€¼CTR'], cmap='RdYlGn', axis=0)
    st.dataframe(styled_df, use_container_width=True, height=400)
    
    st.markdown(f"#### ğŸ“ˆ {view_name} - è¶‹åŠ¿å›¾")
    unique_key = f"ms_{view_name}_{unique_key_prefix}"
    top_labels = display_df['label'].head(5).tolist()
    sel = st.multiselect(f"é€‰æ‹©è¦å¯¹æ¯”çš„{view_name}", display_df['label'].unique(), default=top_labels, key=unique_key)
    if sel:
        plot_df = daily_agg.copy()
        if 'slot_id' in group_cols: plot_df['label'] = plot_df['card_id'] + " (å‘ä½ " + plot_df['slot_id'] + ")"
        else: plot_df['label'] = plot_df['card_id']
        plot_df = plot_df[plot_df['label'].isin(sel)]
        fig = px.line(plot_df, x='date', y='daily_ctr', color='label', markers=True)
        fig.update_yaxes(tickformat=".2%")
        st.plotly_chart(fig, use_container_width=True)

def show_single_analysis(df, label="è¡¨æ ¼ A"):
    st.markdown(f"## ğŸ” {label} - æ·±åº¦åˆ†æ")
    
    enable_internal = st.checkbox("âš”ï¸ å¼€å¯è¡¨å†…æ—¶æ®µå¯¹æ¯”", key=f"ec_{label}")
    if enable_internal:
        show_comparison_logic(df, df, f"{label}-A", f"{label}-B")
        return

    min_d, max_d = df['date'].min(), df['date'].max()
    date_range = st.date_input("é€‰æ‹©æ—¶é—´æ®µ", [min_d, max_d], key=f"d_{label}")
    if len(date_range) != 2: return
    sub_df = df[(df['date'] >= date_range[0]) & (df['date'] <= date_range[1])].copy()
    
    total_exp = sub_df['exposure_uv'].sum()
    total_clk = sub_df['click_uv'].sum()
    weighted_ctr = total_clk / total_exp if total_exp > 0 else 0
    daily_agg = sub_df.groupby('date').agg({'exposure_uv':'sum', 'click_uv':'sum'})
    daily_agg['day_ctr'] = daily_agg['click_uv'] / daily_agg['exposure_uv']
    arithmetic_ctr = daily_agg['day_ctr'].mean()
    
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("æ€»æ›å…‰", f"{total_exp:,.0f}")
    c2.metric("æ€»ç‚¹å‡»", f"{total_clk:,.0f}")
    c3.metric("åŠ æƒå‡å€¼ CTR", f"{weighted_ctr:.2%}")
    c4.metric("ç®—æœ¯å‡å€¼ CTR", f"{arithmetic_ctr:.2%}")
    
    global GLOBAL_DATA_CONTEXT
    GLOBAL_DATA_CONTEXT = f"å•è¡¨åˆ†æ: {label}, CTR: {weighted_ctr:.2%}, ç‚¹å‡»: {total_clk}"
    
    export_df = sub_df.groupby(['card_id', 'slot_id']).agg({'exposure_uv':'sum', 'click_uv':'sum'}).reset_index()
    export_df['weighted_ctr'] = export_df['click_uv'] / export_df['exposure_uv']
    export_df = export_df.sort_values('exposure_uv', ascending=False)
    top_5 = export_df.head(5).rename(columns={'card_id':'å¡ç‰‡ID', 'weighted_ctr':'CTR', 'exposure_uv':'æ›å…‰'})
    
    st.divider()
    t1, t2 = st.tabs(["ğŸ’³ è§†å›¾ä¸€ï¼šåªçœ‹å¡ç‰‡", "ğŸ“ è§†å›¾äºŒï¼šç»†åˆ†å¡ç‰‡+å‘ä½"])
    with t1: render_analysis_view(sub_df, ['card_id'], "å¡ç‰‡ç»´åº¦", label)
    with t2: render_analysis_view(sub_df, ['card_id', 'slot_id'], "å¡ç‰‡+å‘ä½ç»†åˆ†", label)
    
    st.divider()
    st.header("ğŸ“¥ å¯¼å‡ºä¸­å¿ƒ")
    c_e1, c_e2 = st.columns(2)
    word_file = generate_word_report(f"æŠ¥å‘Š-{manual_country}", {"å‘¨æœŸ": str(date_range), "æ›å…‰": f"{total_exp:,.0f}"}, "æ•°æ®é™„è¡¨", {"Top5": top_5})
    excel_file = generate_excel({"èšåˆ": export_df, "æ˜ç»†": sub_df})
    with c_e1: st.download_button("ğŸ“„ ä¸‹è½½ Word", word_file, f"Report_{label}.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document", key=f"bw_{label}")
    with c_e2: st.download_button("ğŸ“Š ä¸‹è½½ Excel", excel_file, f"Data_{label}.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", key=f"be_{label}")

# --- 5. åŒè¡¨å¯¹æ¯” (V37: Dashboard + Charts) ---
def show_comparison_logic(d1_raw, d2_raw, label_a_name="è¡¨æ ¼A", label_b_name="è¡¨æ ¼B"):
    st.markdown("### âš™ï¸ å¯¹æ¯”é…ç½®")
    compare_mode = st.radio("ğŸ‘‰ ç»´åº¦ï¼š", ["ğŸ’³ ä»…å¯¹æ¯”å¡ç‰‡", "ğŸ“ å¯¹æ¯” å¡ç‰‡+å‘ä½"], horizontal=True, key=f"rad_{label_a_name}")
    group_cols = ['card_id'] if "ä»…å¯¹æ¯”å¡ç‰‡" in compare_mode else ['card_id', 'slot_id']
    
    all_cards = sorted(list(set(d1_raw['card_id'].unique()) | set(d2_raw['card_id'].unique())))
    exclude_list = st.multiselect("ğŸš« å‰”é™¤æŒ‡å®šå¡ç‰‡", all_cards, key=f"exc_{label_a_name}")
    
    if exclude_list:
        d1 = d1_raw[~d1_raw['card_id'].isin(exclude_list)].copy()
        d2 = d2_raw[~d2_raw['card_id'].isin(exclude_list)].copy()
    else:
        d1, d2 = d1_raw.copy(), d2_raw.copy()
    
    c1, c2 = st.columns(2)
    with c1: d1_range = st.date_input(f"{label_a_name} æ—¶é—´æ®µ", [d1['date'].min(), d1['date'].max()], key=f"dr1_{label_a_name}")
    with c2: d2_range = st.date_input(f"{label_b_name} æ—¶é—´æ®µ", [d2['date'].min(), d2['date'].max()], key=f"dr2_{label_a_name}")
        
    if len(d1_range)==2 and len(d2_range)==2:
        d1_final = d1[(d1['date'] >= d1_range[0]) & (d1['date'] <= d1_range[1])]
        d2_final = d2[(d2['date'] >= d2_range[0]) & (d2['date'] <= d2_range[1])]
        
        def calc_global(d):
            e = d['exposure_uv'].sum()
            c = d['click_uv'].sum()
            return e, c, (c/e if e>0 else 0)
        
        ea, ca, ctra = calc_global(d1_final)
        eb, cb, ctrb = calc_global(d2_final)
        ctr_multiple = (ctrb / ctra) if ctra > 0 else 0
        exp_diff_pct = (eb - ea) / ea if ea > 0 else 0
        
        # å½’å› 
        top_row = d2_final.groupby('card_id')['click_uv'].sum().sort_values(ascending=False).head(1)
        summary_text_report, top_info = "", "æ— æ˜æ˜¾å¤´éƒ¨"
        
        if not top_row.empty:
            top_id = top_row.index[0]
            top_contrib = top_row.values[0] / cb if cb > 0 else 0
            d1_no = d1_final[d1_final['card_id'] != top_id]
            d2_no = d2_final[d2_final['card_id'] != top_id]
            _, _, ctra_no = calc_global(d1_no)
            _, _, ctrb_no = calc_global(d2_no)
            ctr_mult_no = (ctrb_no / ctra_no) if ctra_no > 0 else 0
            conclusion = "âœ… æ™®æ¶¨å‹" if ctr_mult_no > 1.05 else "âš ï¸ å¤´éƒ¨ä¾èµ–å‹"
            
            st.markdown(f"""
            <div style="background-color: #F0F2F6; padding: 20px; border-radius: 10px; border-left: 6px solid #FF9800; color: #111;">
                <h3 style="margin:0; color: #000;">ğŸ“ æ·±åº¦å½’å› æ€»ç»“</h3>
                1. <b>æ•´ä½“è¡¨ç°ï¼š</b> CTR æ˜¯ä¸Šå‘¨æœŸçš„ <b>{ctr_multiple:.2f} å€</b> ({ctrb:.2%} vs {ctra:.2%})ã€‚<br>
                2. <b>å‰”é™¤éªŒè¯ï¼š</b> å‰”é™¤å¤´éƒ¨ã€{top_id}ã€‘åï¼ŒCTR å€æ•°ä¸º <b>{ctr_mult_no:.2f} å€</b>ã€‚<br>
                <div style="margin-top:5px;">{conclusion}</div>
            </div>
            """, unsafe_allow_html=True)
            summary_text_report = f"å‰”é™¤å¤´éƒ¨ {top_id} åï¼Œå€æ•°ä¸º {ctr_mult_no:.2f}ã€‚ç»“è®º: {conclusion}"
            top_info = f"Top1: {top_id} (è´¡çŒ®{top_contrib:.1%})"
        
        st.subheader("ğŸ“Š å…¨ç›˜æˆ˜æŠ¥")
        k1, k2, k3, k4 = st.columns(4)
        k1.metric("å…¨ç›˜ CTR", f"{ctrb:.2%}", f"{ctrb-ctra:+.2%}", delta_color="normal")
        k2.metric("æ€»æ›å…‰", f"{eb:,.0f}", f"{exp_diff_pct:+.1%}", delta_color="normal")
        k3.metric("æ€»ç‚¹å‡»", f"{cb:,.0f}", f"{(cb-ca)/ca if ca>0 else 0:+.1%}", delta_color="normal")
        
        diag = "âšª å¸¸è§„"
        if exp_diff_pct < -0.2 and (ctrb-ctra) > 0 and (cb-ca) < 0: diag = "âš ï¸ è™šå‡ææ•ˆ (èç¼©)"
        elif exp_diff_pct > 0.2 and (ctrb-ctra) < 0: diag = "ğŸŸ  æµé‡ç¨€é‡Š"
        elif ctr_multiple > 1.05 and (cb-ca) > 0: diag = "ğŸŸ¢ æœ‰æ•ˆå¢é•¿"
        k4.info(diag)
        
        global GLOBAL_DATA_CONTEXT
        GLOBAL_DATA_CONTEXT = f"å¯¹æ¯”æˆ˜æŠ¥\nAè¡¨CTR: {ctra:.2%} Bè¡¨CTR: {ctrb:.2%}\nè¯Šæ–­: {diag}\nå½’å› : {top_info}"

        # === V37 æ–°å¢ï¼šåŒè¡¨å¯¹æ¯” Dashboard ===
        st.divider()
        st.subheader("ğŸ“Š åŒè¡¨å¯¹æ¯”é©¾é©¶èˆ± (Dashboard)")
        
        # å‡†å¤‡æ•°æ®
        stat1 = d1_final.groupby(group_cols).agg({'exposure_uv':'sum', 'click_uv':'sum'}).reset_index()
        stat2 = d2_final.groupby(group_cols).agg({'exposure_uv':'sum', 'click_uv':'sum'}).reset_index()
        stat1 = stat1.rename(columns={'exposure_uv':'Exp_A', 'click_uv':'Clk_A'})
        stat2 = stat2.rename(columns={'exposure_uv':'Exp_B', 'click_uv':'Clk_B'})
        stat1['CTR_A'] = stat1['Clk_A'] / stat1['Exp_A']
        stat2['CTR_B'] = stat2['Clk_B'] / stat2['Exp_B']
        
        comp = pd.merge(stat1, stat2, on=group_cols, how='outer', indicator=True)
        comp['_merge'] = comp['_merge'].astype(str)
        comp = comp.fillna(0)
        def label_status(row):
            if row['_merge'] == 'both': return 'ğŸ”µ å»¶ç»­'
            if row['_merge'] == 'right_only': return 'ğŸŸ¢ æ–°ä¸Šæ¶'
            if row['_merge'] == 'left_only': return 'ğŸ”´ å·²ä¸‹æ¶'
        comp['çŠ¶æ€'] = comp.apply(label_status, axis=1)
        comp['CTRå·®å€¼'] = comp['CTR_B'] - comp['CTR_A']
        
        # Label å¤„ç†
        if 'slot_id' in group_cols:
            comp['label'] = comp['card_id'] + " (" + comp['slot_id'] + ")"
        else:
            comp['label'] = comp['card_id']
            
        # 1. æ ¸å¿ƒå¡ç‰‡å¯¹æ¯”å›¾ (Top 10 High Traffic)
        top_traffic = comp.sort_values('Exp_B', ascending=False).head(10)
        if not top_traffic.empty:
            fig_bar = plot_paired_bar(top_traffic, 'label', 'CTR_A', 'CTR_B', "ğŸ”¥ æµé‡ Top 10 å¡ç‰‡ CTR å¯¹æ¯” (A vs B)")
            st.plotly_chart(fig_bar, use_container_width=True)
            
        # 2. è´¡çŒ®åº¦å›¾ (Impact)
        # è´¡çŒ®åº¦ = (CTR_B - CTR_A) * æƒé‡(è¿™é‡Œç®€å•ç”¨å¹³å‡æ›å…‰å æ¯”è¿‘ä¼¼)
        comp['Impact'] = comp['CTRå·®å€¼'] * ((comp['Exp_A'] + comp['Exp_B'])/2)
        top_impact = comp.sort_values('Impact', ascending=False).head(5) # æ‹‰å‡ Top 5
        bot_impact = comp.sort_values('Impact', ascending=True).head(5) # æ‹–ç´¯ Top 5
        impact_df = pd.concat([top_impact, bot_impact])
        
        fig_impact = plot_impact_diverging(impact_df, 'label', 'CTRå·®å€¼', "ğŸ† æ¶¨è·Œå¹… Top æ¦œ (çº¢æ¶¨ç»¿è·Œ)")
        st.plotly_chart(fig_impact, use_container_width=True)

        st.divider()
        st.subheader("ğŸ“‹ è¯¦ç»†æ•°æ®è¡¨")
        comp = comp.sort_values(['çŠ¶æ€', 'CTRå·®å€¼'])
        show_cols = ['çŠ¶æ€'] + group_cols + ['CTR_A', 'CTR_B', 'CTRå·®å€¼', 'Exp_A', 'Exp_B']
        fmt = {'CTR_A':'{:.2%}', 'CTR_B':'{:.2%}', 'CTRå·®å€¼':'{:+.2%}', 'Exp_A':'{:,.0f}', 'Exp_B':'{:,.0f}'}
        def highlight_status(val):
            if 'æ–°' in str(val): return 'color: green; font-weight: bold'
            if 'ä¸‹æ¶' in str(val): return 'color: red; font-weight: bold'
            return 'color: blue'
        st.dataframe(comp[show_cols].style.format(fmt).applymap(highlight_status, subset=['çŠ¶æ€']).background_gradient(subset=['CTRå·®å€¼'], cmap='RdYlGn', vmin=-0.02, vmax=0.02), use_container_width=True)
        
        st.divider()
        st.header("ğŸ“¥ å¯¼å‡ºä¸­å¿ƒ")
        c_ex1, c_ex2 = st.columns(2)
        word_file = generate_word_report(f"å¯¹æ¯”æˆ˜æŠ¥-{manual_country}", {"CTRå˜åŒ–": f"{ctra:.2%}->{ctrb:.2%}"}, summary_text_report, {"çº¢æ¦œ": top_impact, "é»‘æ¦œ": bot_impact})
        excel_file = generate_excel({"å…¨ç›˜": comp, "çº¢æ¦œ": top_impact})
        with c_ex1: st.download_button("ğŸ“„ ä¸‹è½½ Word", word_file, f"Report_Compare_{label_a_name}.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document", key=f"bw_{label_a_name}")
        with c_ex2: st.download_button("ğŸ“Š ä¸‹è½½ Excel", excel_file, f"Data_Compare_{label_a_name}.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", key=f"be_{label_a_name}")

def show_comparison(df1, df2):
    show_comparison_logic(df1, df2, "è¡¨æ ¼A", "è¡¨æ ¼B")

# --- ä¸»é€»è¾‘ ---
df_a = None
if file_a: df_a = process_data(file_a, sheet_name_a, visible_only=read_visible_only)
df_b = None
if file_b: df_b = process_data(file_b, sheet_name_b, visible_only=read_visible_only)

if df_a is not None:
    if df_b is not None:
        mode = st.radio("ğŸ‘‡ æ¨¡å¼", ["ğŸ“„ å•æ–‡ä»¶åˆ†æ", "âš”ï¸ åŒè¡¨å¯¹æ¯”"], horizontal=True)
        st.divider()
        if mode == "ğŸ“„ å•æ–‡ä»¶åˆ†æ":
            t1, t2 = st.tabs(["è¡¨æ ¼ A", "è¡¨æ ¼ B"])
            with t1: show_single_analysis(df_a, "è¡¨æ ¼ A")
            with t2: show_single_analysis(df_b, "è¡¨æ ¼ B")
        else:
            show_comparison(df_a, df_b)
    else:
        show_single_analysis(df_a, "è¡¨æ ¼ A")
else:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¸Šä¼  Excel æ–‡ä»¶ã€‚")

if GLOBAL_DATA_CONTEXT != "æš‚æ— æ•°æ®ã€‚":
    init_ai_sidebar(GLOBAL_DATA_CONTEXT)
