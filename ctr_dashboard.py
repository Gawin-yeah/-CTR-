import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from openai import OpenAI
import io
from docx import Document
from docx.shared import Pt
from docx.enum.text import WD_ALIGN_PARAGRAPH
from openpyxl import load_workbook

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="CTR ç»ˆæç¨³å®šç³»ç»Ÿ (V56)", layout="wide")
st.title("ğŸ¯ é¦–é¡µå¡ç‰‡ CTR ç»ˆæç¨³å®šç³»ç»Ÿ (V56.0)")

# ==========================================
# ğŸ§  0. çŠ¶æ€è®°å¿†
# ==========================================
if 'persist_ex_a' not in st.session_state: st.session_state.persist_ex_a = []
if 'persist_ex_b' not in st.session_state: st.session_state.persist_ex_b = []
if 'persist_ex_dual' not in st.session_state: st.session_state.persist_ex_dual = []
if 'persist_in_a' not in st.session_state: st.session_state.persist_in_a = []
if 'persist_in_b' not in st.session_state: st.session_state.persist_in_b = []
if 'persist_in_dual' not in st.session_state: st.session_state.persist_in_dual = []

def update_ex_a(): st.session_state.persist_ex_a = st.session_state.k_ex_a
def update_ex_b(): st.session_state.persist_ex_b = st.session_state.k_ex_b
def update_ex_dual(): st.session_state.persist_ex_dual = st.session_state.k_ex_dual
def update_in_a(): st.session_state.persist_in_a = st.session_state.k_in_a
def update_in_b(): st.session_state.persist_in_b = st.session_state.k_in_b
def update_in_dual(): st.session_state.persist_in_dual = st.session_state.k_in_dual

# ==========================================
# ğŸ› ï¸ ç»˜å›¾ä¸å·¥å…·å‡½æ•°
# ==========================================
def plot_waterfall(df_waterfall, title):
    fig = go.Figure(go.Waterfall(
        name="20", orientation="v",
        measure=df_waterfall['measure'],
        x=df_waterfall['category'],
        textposition="outside",
        text=df_waterfall['text_val'],
        y=df_waterfall['value'],
        connector={"line": {"color": "rgb(63, 63, 63)"}},
        decreasing={"marker": {"color": "#EF553B"}},
        increasing={"marker": {"color": "#00CC96"}},
        totals={"marker": {"color": "#636EFA"}}
    ))
    fig.update_layout(title=title, showlegend=False, template="plotly_white", height=450)
    return fig

def plot_dual_axis(df, x_col, bar_col, line_col, title):
    fig = go.Figure()
    fig.add_trace(go.Bar(x=df[x_col], y=df[bar_col], name="æ€»æ›å…‰", marker_color='#A9CCE3', opacity=0.6, yaxis='y1'))
    fig.add_trace(go.Scatter(x=df[x_col], y=df[line_col], name="CTR", mode='lines+markers', line=dict(color='#E74C3C', width=3), marker=dict(size=8), yaxis='y2'))
    fig.update_layout(title=title, xaxis_title="æ—¥æœŸ", yaxis=dict(title="æ›å…‰", side="left", showgrid=False), yaxis2=dict(title="CTR", side="right", overlaying="y", tickformat=".2%", showgrid=True), hovermode="x unified", legend=dict(orientation="h", y=1.1), template="plotly_white", height=400)
    return fig

def plot_bar_race(df, x_col, y_col, title):
    df[y_col] = df[y_col].astype(str)
    fig = px.bar(df, x=x_col, y=y_col, orientation='h', title=title, text_auto='.2%', color=x_col, color_continuous_scale='Blues')
    fig.update_layout(yaxis={'categoryorder':'total ascending', 'type': 'category'}, template="plotly_white", height=350, showlegend=False)
    return fig

def plot_pie(df, names, values, title):
    fig = px.pie(df, names=names, values=values, title=title, hole=0.4)
    fig.update_layout(template="plotly_white", height=350)
    return fig

def plot_paired_bar(df, category_col, val_a, val_b, title):
    df[category_col] = df[category_col].astype(str)
    df_melt = df.melt(id_vars=[category_col], value_vars=[val_a, val_b], var_name='æ—¶æœŸ', value_name='CTR')
    df_melt['æ—¶æœŸ'] = df_melt['æ—¶æœŸ'].map({val_a: 'æ—¶æœŸA', val_b: 'æ—¶æœŸB'})
    fig = px.bar(df_melt, y=category_col, x='CTR', color='æ—¶æœŸ', barmode='group', orientation='h', text_auto='.2%', title=title)
    fig.update_layout(yaxis={'categoryorder':'total ascending', 'type': 'category'}, xaxis_tickformat=".2%", height=500, legend=dict(orientation="h", y=1.1))
    return fig

def plot_impact_diverging(df, category_col, impact_col, title):
    df[category_col] = df[category_col].astype(str)
    df['Color'] = df[impact_col].apply(lambda x: '#E74C3C' if x >= 0 else '#2ECC71')
    fig = go.Figure(go.Bar(y=df[category_col], x=df[impact_col], orientation='h', marker=dict(color=df['Color']), text=df[impact_col], texttemplate='%{text:+.2%}', textposition='outside'))
    fig.update_layout(title=title, yaxis={'categoryorder':'total ascending', 'type': 'category'}, xaxis_tickformat=".2%", height=500)
    return fig

def generate_excel(dfs_dict):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        for sheet_name, df in dfs_dict.items():
            safe_name = sheet_name[:30]
            df.to_excel(writer, sheet_name=safe_name, index=False)
    return output.getvalue()

def generate_word_report(title, metrics, summary_text, tables_data):
    doc = Document()
    doc.add_heading(title, 0).alignment = WD_ALIGN_PARAGRAPH.CENTER
    doc.add_paragraph(f"ç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}")
    doc.add_heading('ä¸€ã€æ ¸å¿ƒå¤§ç›˜æˆ˜æŠ¥', level=1)
    p = doc.add_paragraph()
    for k, v in metrics.items(): p.add_run(f"{k}: {v}\n").bold = True
    doc.add_heading('äºŒã€æ·±åº¦å½’å› ä¸æ´å¯Ÿ', level=1)
    doc.add_paragraph(summary_text)
    for t_title, df in tables_data.items():
        if df.empty: continue
        doc.add_heading(f"ä¸‰ã€{t_title}", level=1)
        t = doc.add_table(rows=1, cols=len(df.columns))
        t.style = 'Table Grid'
        for i, c in enumerate(df.columns): t.rows[0].cells[i].text = str(c)
        for _, r in df.iterrows():
            row = t.add_row()
            for i, v in enumerate(r):
                row.cells[i].text = f"{v:.2%}" if isinstance(v, float) and abs(v)<1 else str(v)
    output = io.BytesIO()
    doc.save(output)
    return output.getvalue()

# ==========================================
# ğŸ¤– AI åŠ©æ‰‹
# ==========================================
def init_ai_sidebar(context_data):
    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ¤– AI æ™ºèƒ½åˆ†æåŠ©æ‰‹")
    with st.sidebar.expander("âš™ï¸ æ¨¡å‹é…ç½®", expanded=False):
        api_key = st.text_input("API Key", type="password")
        base_url = st.text_input("Base URL", value="https://api.deepseek.com")
        model_name = st.text_input("Model Name", value="deepseek-chat")
    
    if "messages" not in st.session_state: st.session_state.messages = []
    for msg in st.session_state.messages:
        with st.sidebar.chat_message(msg["role"]): st.markdown(msg["content"])
    
    if prompt := st.sidebar.chat_input("é—®æˆ‘..."):
        if not api_key: st.sidebar.error("è¯·å¡«å…¥ API Key")
        else:
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.sidebar.chat_message("user"): st.markdown(prompt)
            with st.sidebar.chat_message("assistant"):
                msg_ph = st.empty()
                full_res = ""
                try:
                    client = OpenAI(api_key=api_key, base_url=base_url)
                    stream = client.chat.completions.create(
                        model=model_name,
                        messages=[{"role": "system", "content": f"åŸºäºæ•°æ®å›ç­”ï¼š\n{context_data}"}] + [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
                        stream=True,
                    )
                    for chunk in stream:
                        if chunk.choices[0].delta.content:
                            full_res += chunk.choices[0].delta.content
                            msg_ph.markdown(full_res + "â–Œ")
                    msg_ph.markdown(full_res)
                    st.session_state.messages.append({"role": "assistant", "content": full_res})
                except Exception as e: st.error(str(e))

GLOBAL_DATA_CONTEXT = "æš‚æ— æ•°æ®ã€‚"

# ==========================================
# ğŸ“‚ æ•°æ®æ¥å…¥
# ==========================================
st.sidebar.header("1. æ•°æ®æ¥å…¥")
manual_country = st.sidebar.text_input("âœï¸ æ‰€å±å›½å®¶", value="US").upper()
read_visible_only = st.sidebar.checkbox("ğŸ‘ï¸ åªè¯»å–æ˜¾ç¤ºè¡Œ (å‰”é™¤ç­›é€‰éšè—)", value=False)

file_a = st.sidebar.file_uploader("ä¸Šä¼ ä¸»è¡¨æ ¼ (A)", type=["xlsx", "xls", "csv"], key="file_a")
sheet_name_a = 0
if file_a and file_a.name.endswith(('xlsx', 'xls')):
    try:
        xls = pd.ExcelFile(file_a)
        if len(xls.sheet_names) > 1: sheet_name_a = st.sidebar.selectbox(f"è¡¨Aå·¥ä½œè¡¨:", xls.sheet_names, key="s_a")
    except: pass

file_b = st.sidebar.file_uploader("ä¸Šä¼ å¯¹æ¯”è¡¨æ ¼ (B)", type=["xlsx", "xls", "csv"], key="file_b")
sheet_name_b = 0
if file_b and file_b.name.endswith(('xlsx', 'xls')):
    try:
        xls = pd.ExcelFile(file_b)
        if len(xls.sheet_names) > 1: sheet_name_b = st.sidebar.selectbox(f"è¡¨Bå·¥ä½œè¡¨:", xls.sheet_names, key="s_b")
    except: pass

st.sidebar.markdown("---")
min_exp_noise = st.sidebar.number_input("ğŸ“‰ å•æ—¥æœ€å°æ›å…‰é˜ˆå€¼ (å»å™ª)", value=50, step=50)

def extract_start_date(s):
    s = str(s).strip()
    if "~" in s: return s.split("~")[0].strip()
    if "ï½" in s: return s.split("ï½")[0].strip()
    return s

@st.cache_data
def process_data(file, sheet_name=0, visible_only=False):
    try:
        if file.name.endswith('.csv'):
            raw_df = pd.read_csv(file)
        elif visible_only:
            wb = load_workbook(file, data_only=True, read_only=False)
            ws = wb.active if sheet_name == 0 else wb[sheet_name]
            data = []
            rows = ws.iter_rows(values_only=False)
            headers = None
            for row in rows:
                if ws.row_dimensions[row[0].row].hidden: continue
                vals = [c.value for c in row]
                if headers is None: headers = vals
                else: data.append(vals)
            raw_df = pd.DataFrame(data, columns=headers)
        else:
            raw_df = pd.read_excel(file, sheet_name=sheet_name)
            
        rename_map = {}
        for col in raw_df.columns:
            if "å¡ç‰‡" in col or "Card" in col: rename_map[col] = 'card_id'
            elif "å‘ä½" in col or "Slot" in col: rename_map[col] = 'slot_id'
            elif "æŒ‡æ ‡" in col: rename_map[col] = 'metric_name'
        df = raw_df.rename(columns=rename_map)
        
        required = ['card_id', 'metric_name']
        if not all(col in df.columns for col in required): return None
        
        if 'slot_id' not in df.columns: df['slot_id'] = 'Default'
        df['card_id'] = df['card_id'].astype(str)
        df['slot_id'] = df['slot_id'].astype(str)
        
        fixed = ['card_id', 'slot_id', 'metric_name', 'åˆè®¡', 'å‡å€¼', 'æ€»è®¡', 'Total']
        dates = [c for c in df.columns if c not in fixed and "Unnamed" not in str(c)]
        if not dates: return None
        
        melted = df.melt(id_vars=['card_id', 'slot_id', 'metric_name'], value_vars=dates, var_name='raw_date', value_name='count')
        melted['date'] = pd.to_datetime(melted['raw_date'].apply(extract_start_date), errors='coerce').dt.date
        melted = melted.dropna(subset=['date'])
        melted['count'] = pd.to_numeric(melted['count'], errors='coerce').fillna(0)
        
        def get_type(t):
            if "æ›å…‰" in str(t): return "exposure_uv"
            if "ç‚¹å‡»" in str(t): return "click_uv"
            return None
        melted['type'] = melted['metric_name'].apply(get_type)
        melted = melted.dropna(subset=['type'])
        
        final = melted.pivot_table(index=['date', 'card_id', 'slot_id'], columns='type', values='count', aggfunc='sum').reset_index()
        for c in ['exposure_uv', 'click_uv']:
            if c not in final.columns: final[c] = 0
        return final
    except: return None

def filter_dataframe(df, min_exp):
    if df is None: return None
    return df[(df['exposure_uv'] >= min_exp) & (df['click_uv'] <= df['exposure_uv'])].copy()

# --- 4. å•æ–‡ä»¶è§†å›¾ (V56 ä¿®å¤ç‰ˆ) ---
def render_analysis_view(data, group_cols, view_name, unique_key_prefix):
    # 1. è®¡ç®—æ ¸å¿ƒæŒ‡æ ‡ (åŸºç¡€è¡¨)
    period = data.groupby(group_cols).agg({'exposure_uv':'sum', 'click_uv':'sum'}).reset_index()
    period['åŠ æƒCTR'] = period['click_uv']/period['exposure_uv']
    
    daily = data.groupby(group_cols + ['date']).agg({'exposure_uv':'sum', 'click_uv':'sum'}).reset_index()
    daily['daily_ctr'] = daily['click_uv']/daily['exposure_uv']
    
    arith = daily.groupby(group_cols)['daily_ctr'].mean().reset_index().rename(columns={'daily_ctr':'ç®—æœ¯CTR'})
    
    # base_df åªåŒ…å«æ±‡æ€»æ•°æ®ï¼Œä¸åŒ…å«æ—¥æœŸåˆ—ï¼Œé¿å…å†²çª
    base_df = pd.merge(period, arith, on=group_cols, how='left').sort_values('exposure_uv', ascending=False)
    
    # Label å¤„ç†
    display_base = base_df.copy()
    if 'slot_id' in group_cols: display_base['label'] = display_base['card_id'] + " (" + display_base['slot_id'] + ")"
    else: display_base['label'] = display_base['card_id']
    
    # ä»ªè¡¨ç›˜
    with st.expander(f"ğŸ“Š {view_name} - Leader é©¾é©¶èˆ±", expanded=True):
        c1, c2 = st.columns(2)
        with c1: st.plotly_chart(plot_pie(display_base.head(8), 'label', 'exposure_uv', "æµé‡ Top 8"), use_container_width=True)
        with c2: 
            top_ctr = display_base[display_base['exposure_uv'] > data['exposure_uv'].mean()*0.1].head(10)
            if not top_ctr.empty:
                st.plotly_chart(plot_bar_race(top_ctr, 'åŠ æƒCTR', 'label', "é«˜æ½œ Top 10"), use_container_width=True)
            else: st.info("æ•°æ®ä¸è¶³")

    st.markdown("---")
    st.markdown(f"#### ğŸ“‹ è¯¦ç»†æ•°æ®é€è§† ({view_name})")
    
    c_s1, c_s2 = st.columns([2, 1])
    with c_s1:
        search_vals = st.multiselect(f"ğŸ” æœç´¢/ç­›é€‰å¡ç‰‡", display_base['label'].unique(), key=f"search_{unique_key_prefix}")
    with c_s2:
        table_metric = st.radio("ğŸ“Š è¡¨æ ¼å±•ç¤ºæ¯æ—¥æŒ‡æ ‡:", ["æ¯æ—¥ CTR", "æ¯æ—¥ æ›å…‰", "æ¯æ—¥ ç‚¹å‡»"], horizontal=True, key=f"tm_{unique_key_prefix}")
    
    # åŠ¨æ€è®¡ç®— Pivotï¼Œé¿å…åˆ—åå†²çª
    if table_metric == "æ¯æ—¥ CTR":
        val_col, fmt_str = 'daily_ctr', '{:.2%}'
    elif table_metric == "æ¯æ—¥ æ›å…‰":
        val_col, fmt_str = 'exposure_uv', '{:,.0f}'
    else:
        val_col, fmt_str = 'click_uv', '{:,.0f}'
        
    pivot = daily.pivot_table(index=group_cols, columns='date', values=val_col, aggfunc='sum' if val_col != 'daily_ctr' else 'mean')
    pivot.columns = [d.strftime('%m-%d') for d in pivot.columns]
    
    # è¿™é‡Œçš„ merge æ˜¯å®‰å…¨çš„ï¼Œå› ä¸º base_df æ²¡æœ‰æ—¥æœŸåˆ—
    final_display = pd.merge(display_base, pivot, on=group_cols, how='left')
    
    if search_vals:
        final_display = final_display[final_display['label'].isin(search_vals)]
    
    cols = ['card_id', 'slot_id', 'åŠ æƒCTR', 'ç®—æœ¯CTR', 'exposure_uv', 'click_uv'] if 'slot_id' in group_cols else ['card_id', 'åŠ æƒCTR', 'ç®—æœ¯CTR', 'exposure_uv', 'click_uv']
    cols += [c for c in pivot.columns]
    
    fmt = {'åŠ æƒCTR':'{:.2%}', 'ç®—æœ¯CTR':'{:.2%}', 'exposure_uv':'{:.0f}', 'click_uv':'{:.0f}'}
    for c in pivot.columns: fmt[c] = fmt_str
    
    st.dataframe(final_display[cols].style.format(fmt).background_gradient(subset=['åŠ æƒCTR'], cmap='RdYlGn', axis=0), use_container_width=True, height=500)

    st.markdown("#### ğŸ“ˆ è¶‹åŠ¿ä¸‹é’»")
    default_trend = search_vals if search_vals else []
    sel = st.multiselect(f"é€‰æ‹©å¯¹è±¡ç”»å›¾", display_base['label'].unique(), default=default_trend, key=f"ms_{unique_key_prefix}")
    if sel:
        metric_choice = st.radio("è¶‹åŠ¿æŒ‡æ ‡:", ["âœ¨ CTR", "ğŸ“Š æ›å…‰é‡", "ğŸ‘† ç‚¹å‡»é‡"], horizontal=True, key=f"rd_{unique_key_prefix}")
        plot_df = daily.copy()
        if 'slot_id' in group_cols: plot_df['label'] = plot_df['card_id'] + " (" + plot_df['slot_id'] + ")"
        else: plot_df['label'] = plot_df['card_id']
        plot_df = plot_df[plot_df['label'].isin(sel)]
        
        if metric_choice == "âœ¨ CTR": y_col, fmt_p = 'daily_ctr', ".2%"
        elif metric_choice == "ğŸ“Š æ›å…‰é‡": y_col, fmt_p = 'exposure_uv', ".0f"
        else: y_col, fmt_p = 'click_uv', ".0f"
            
        st.plotly_chart(px.line(plot_df, x='date', y=y_col, color='label', markers=True).update_yaxes(tickformat=fmt_p), use_container_width=True)

def show_single_analysis(df, label="è¡¨æ ¼ A", is_secondary=False):
    if label == "è¡¨æ ¼ A":
        key_ex, key_in = "k_ex_a", "k_in_a"
        def_ex, def_in = st.session_state.persist_ex_a, st.session_state.persist_in_a
        cb_ex, cb_in = update_ex_a, update_in_a
    elif label == "è¡¨æ ¼ B":
        key_ex, key_in = "k_ex_b", "k_in_b"
        def_ex, def_in = st.session_state.persist_ex_b, st.session_state.persist_in_b
        cb_ex, cb_in = update_ex_b, update_in_b
    else: 
        key_ex, key_in = f"ex_{label}", f"in_{label}"
        def_ex, def_in = [], []
        cb_ex, cb_in = None, None

    st.markdown(f"## ğŸ” {label} - æ·±åº¦åˆ†æ")
    
    if not is_secondary:
        if st.checkbox("âš”ï¸ å¼€å¯è¡¨å†…å¯¹æ¯”", key=f"sw_{label}"):
            show_comparison_logic(df, df, f"{label}-A", f"{label}-B")
            return

    all_cards = sorted(df['card_id'].unique())
    valid_def_in = [x for x in def_in if x in all_cards]
    valid_def_ex = [x for x in def_ex if x in all_cards]

    col_f1, col_f2 = st.columns(2)
    with col_f1:
        include_list = st.multiselect("âœ… åªçœ‹æŒ‡å®šå¡ç‰‡", all_cards, default=valid_def_in, key=key_in, on_change=cb_in)
    with col_f2:
        exclude_list = st.multiselect("ğŸš« å‰”é™¤æŒ‡å®šå¡ç‰‡", all_cards, default=valid_def_ex, key=key_ex, on_change=cb_ex)
    
    sub_df_raw = df.copy()
    if include_list: sub_df_raw = sub_df_raw[sub_df_raw['card_id'].isin(include_list)]
    if exclude_list: sub_df_raw = sub_df_raw[~sub_df_raw['card_id'].isin(exclude_list)]
    
    min_d, max_d = sub_df_raw['date'].min(), sub_df_raw['date'].max()
    dr = st.date_input("é€‰æ‹©å‘¨æœŸ", [min_d, max_d], key=f"dr_{label}")
    if len(dr) != 2: return
    
    sub = sub_df_raw[(sub_df_raw['date']>=dr[0]) & (sub_df_raw['date']<=dr[1])].copy()
    
    e_tot = sub['exposure_uv'].sum()
    c_tot = sub['click_uv'].sum()
    ctr_w = c_tot/e_tot if e_tot>0 else 0
    daily_g = sub.groupby('date').agg({'exposure_uv':'sum', 'click_uv':'sum'}).reset_index()
    daily_g['ctr'] = daily_g['click_uv']/daily_g['exposure_uv']
    
    st.markdown("### ğŸŒ å…¨ç›˜è¶‹åŠ¿é©¾é©¶èˆ±")
    st.plotly_chart(plot_dual_axis(daily_g, 'date', 'exposure_uv', 'ctr', "å…¨ç›˜æµé‡ vs æ•ˆç‡"), use_container_width=True)
    
    c1, c2, c3 = st.columns(3)
    c1.metric("æ€»æ›å…‰", f"{e_tot:,.0f}")
    c2.metric("æ€»ç‚¹å‡»", f"{c_tot:,.0f}")
    c3.metric("åŠ æƒå‡å€¼ CTR", f"{ctr_w:.2%}")
    
    if not is_secondary:
        global GLOBAL_DATA_CONTEXT
        GLOBAL_DATA_CONTEXT = f"å•è¡¨:{label}, å‰”é™¤:{exclude_list}, CTR:{ctr_w:.2%}, æ›å…‰:{e_tot}"
    
    st.divider()
    t1, t2 = st.tabs(["ğŸ’³ è§†å›¾:åªçœ‹å¡ç‰‡", "ğŸ“ è§†å›¾:ç»†åˆ†å‘ä½"])
    with t1: render_analysis_view(sub, ['card_id'], "å¡ç‰‡ç»´åº¦", label+"1")
    with t2: render_analysis_view(sub, ['card_id', 'slot_id'], "å‘ä½ç»´åº¦", label+"2")
    
    st.divider()
    st.header("ğŸ“¥ å¯¼å‡ºä¸­å¿ƒ")
    c_e1, c_e2 = st.columns(2)
    export_df = sub.groupby(['card_id', 'slot_id']).agg({'exposure_uv':'sum', 'click_uv':'sum'}).reset_index()
    export_df['weighted_ctr'] = export_df['click_uv'] / export_df['exposure_uv']
    export_df = export_df.sort_values('exposure_uv', ascending=False)
    top_5 = export_df.head(5).rename(columns={'card_id':'å¡ç‰‡ID', 'weighted_ctr':'CTR', 'exposure_uv':'æ›å…‰'})
    
    word_file = generate_word_report(f"æŠ¥å‘Š-{manual_country}", {"å‘¨æœŸ": str(dr), "æ›å…‰": f"{e_tot:,.0f}", "CTR": f"{ctr_w:.2%}"}, "æ•°æ®è¯¦è§é™„è¡¨", {"Top5": top_5})
    excel_file = generate_excel({"èšåˆ": export_df, "æ˜ç»†": sub})
    with c_e1: st.download_button("ğŸ“„ Word æŠ¥å‘Š", word_file, f"Report_{label}.docx", key=f"bw_{label}")
    with c_e2: st.download_button("ğŸ“Š Excel æ•°æ®", excel_file, f"Data_{label}.xlsx", key=f"be_{label}")

# --- 5. åŒè¡¨å¯¹æ¯” ---
def show_comparison_logic(d1_raw, d2_raw, la="A", lb="B"):
    st.markdown("### âš™ï¸ å¯¹æ¯”é…ç½®")
    mode = st.radio("ç»´åº¦", ["ğŸ’³ ä»…å¡ç‰‡", "ğŸ“ å¡ç‰‡+å‘ä½"], horizontal=True, key=f"rd_{la}")
    cols = ['card_id'] if "ä»…" in mode else ['card_id', 'slot_id']
    
    all_cards = sorted(list(set(d1_raw['card_id'])|set(d2_raw['card_id'])))
    
    if la == "è¡¨æ ¼A": 
        key_ex, key_in = "k_ex_dual", "k_in_dual"
        def_ex, def_in = st.session_state.persist_ex_dual, st.session_state.persist_in_dual
        cb_ex, cb_in = update_ex_dual, update_in_dual
    else: 
        key_ex, key_in = f"ex_{la}", f"in_{la}"
        def_ex, def_in = [], []
        cb_ex, cb_in = None, None

    valid_def_in = [x for x in def_in if x in all_cards]
    valid_def_ex = [x for x in def_ex if x in all_cards]

    col_f1, col_f2 = st.columns(2)
    with col_f1:
        inc = st.multiselect("âœ… åªçœ‹æŒ‡å®šå¡ç‰‡", all_cards, default=valid_def_in, key=key_in, on_change=cb_in)
    with col_f2:
        excl = st.multiselect("ğŸš« å‰”é™¤æŒ‡å®šå¡ç‰‡", all_cards, default=valid_def_ex, key=key_ex, on_change=cb_ex)
    
    d1, d2 = d1_raw.copy(), d2_raw.copy()
    if inc:
        d1 = d1[d1['card_id'].isin(inc)]
        d2 = d2[d2['card_id'].isin(inc)]
    if excl:
        d1 = d1[~d1['card_id'].isin(excl)]
        d2 = d2[~d2['card_id'].isin(excl)]
    
    c1, c2 = st.columns(2)
    dr1 = c1.date_input(f"{la} æ—¶é—´", [d1['date'].min(), d1['date'].max()], key=f"d1_{la}")
    dr2 = c2.date_input(f"{lb} æ—¶é—´", [d2['date'].min(), d2['date'].max()], key=f"d2_{la}")
    
    if len(dr1)==2 and len(dr2)==2:
        d1f = d1[(d1['date']>=dr1[0])&(d1['date']<=dr1[1])]
        d2f = d2[(d2['date']>=dr2[0])&(d2['date']<=dr2[1])]
        
        s1 = d1f.groupby(cols).agg({'exposure_uv':'sum', 'click_uv':'sum'}).reset_index()
        s2 = d2f.groupby(cols).agg({'exposure_uv':'sum', 'click_uv':'sum'}).reset_index()
        
        tea, tca = s1['exposure_uv'].sum(), s1['click_uv'].sum()
        teb, tcb = s2['exposure_uv'].sum(), s2['click_uv'].sum()
        ctra, ctrb = (tca/tea if tea>0 else 0), (tcb/teb if teb>0 else 0)
        
        df_m = pd.merge(s1, s2, on=cols, how='outer', suffixes=('_A', '_B')).fillna(0)
        df_m['CTRA'] = df_m.apply(lambda r: r['click_uv_A']/r['exposure_uv_A'] if r['exposure_uv_A']>0 else 0, axis=1)
        df_m['CTRB'] = df_m.apply(lambda r: r['click_uv_B']/r['exposure_uv_B'] if r['exposure_uv_B']>0 else 0, axis=1)
        
        df_m['WA'] = df_m['exposure_uv_A']/tea if tea>0 else 0
        df_m['WB'] = df_m['exposure_uv_B']/teb if teb>0 else 0
        
        df_m['IsNew'] = df_m['exposure_uv_A'] == 0
        df_m['IsLost'] = df_m['exposure_uv_B'] == 0
        df_m['IsCommon'] = (~df_m['IsNew']) & (~df_m['IsLost'])
        
        rate_eff = df_m[df_m['IsCommon']].apply(lambda r: (r['CTRB']-r['CTRA'])*r['WA'], axis=1).sum()
        mix_eff = df_m[df_m['IsCommon']].apply(lambda r: (r['WB']-r['WA'])*r['CTRA'], axis=1).sum()
        new_eff = df_m[df_m['IsNew']].apply(lambda r: (r['CTRB']-ctra)*r['WB'], axis=1).sum()
        lost_eff = df_m[df_m['IsLost']].apply(lambda r: (ctra-r['CTRA'])*r['WA'], axis=1).sum()
        
        df_m['Contrib'] = (df_m['click_uv_B']/teb if teb>0 else 0) - (df_m['click_uv_A']/tea if tea>0 else 0)
        
        ctr_diff = ctrb - ctra
        wf_df = pd.DataFrame({
            "measure": ["absolute", "relative", "relative", "relative", "relative", "total"],
            "category": ["A (åŸºå‡†)", "å­˜é‡è¡¨ç°", "æµé‡ç»“æ„", "æ–°å¡çº¢åˆ©", "ä¸‹æ¶/å…¶ä»–", "B (å½“å‰)"],
            "value": [ctra, rate_eff, mix_eff, new_eff, ctrb-ctra-rate_eff-mix_eff-new_eff, None],
            "text_val": [f"{ctra:.2%}", f"{rate_eff:+.2%}", f"{mix_eff:+.2%}", f"{new_eff:+.2%}", "Diff", f"{ctrb:.2%}"]
        })
        
        conclusion = ""
        if ctr_diff > 0:
            if new_eff > abs(rate_eff) and rate_eff < 0:
                conclusion = "ğŸš€ **æ–°å¡é©±åŠ¨å‹**ï¼šæœ¬å‘¨æœŸ CTR æå‡ä¸»è¦æ˜¯ç”±**æ–°ç´ æ**é©±åŠ¨çš„ã€‚\nâš ï¸ **è­¦æƒ•**ï¼šå­˜é‡è€å¡ç‰‡è¡¨ç°ç–²è½¯ï¼ˆå­˜é‡è¡¨ç°ä¸ºè´Ÿï¼‰ï¼Œä¸”æµé‡åˆ†é…æ•ˆç‡å¯èƒ½ä¸‹é™ã€‚"
            elif rate_eff > 0 and new_eff > 0:
                conclusion = "ğŸŒŸ **å…¨é¢æ™®æ¶¨**ï¼šå­˜é‡å¡ç‰‡è´¨é‡æå‡ï¼Œä¸”æ–°å¡è¡¨ç°ä¼˜å¼‚ï¼Œä¸šåŠ¡å¤„äºå¥åº·å¢é•¿æœŸã€‚"
            else:
                conclusion = "ğŸ“ˆ **ç¨³æ­¥å¢é•¿**ï¼šå„é¡¹æŒ‡æ ‡å‡ä¸ºæ­£å‘è´¡çŒ®ã€‚"
        else:
            conclusion = "ğŸ“‰ **å¤§ç›˜å›è½**ï¼šéœ€å…³æ³¨è´Ÿå‘è´¡çŒ®æœ€å¤§çš„å› å­ã€‚"

        k1, k2, k3, k4 = st.columns(4)
        k1.metric("CTR", f"{ctrb:.2%}", f"{ctrb-ctra:+.2%}")
        k2.metric("å€æ•°", f"{ctrb/ctra:.2f}x" if ctra>0 else "âˆ")
        k3.metric("æ›å…‰", f"{teb:,.0f}", f"{(teb-tea)/tea:+.1%}" if tea>0 else "âˆ")
        k4.metric("ç‚¹å‡»", f"{tcb:,.0f}", f"{(tcb-tca)/tca:+.1%}" if tca>0 else "âˆ")
        
        c_w, c_t = st.columns([2, 1])
        with c_w: 
            st.plotly_chart(plot_waterfall(wf_df, "CTR æ¶¨è·Œå½’å› ç€‘å¸ƒ"), use_container_width=True)
            with st.expander("ğŸ“– è¯»æ‡‚è¿™å¼ å›¾ (åè¯è§£é‡Š)"):
                st.markdown("- **å­˜é‡è¡¨ç°**: è€å¡ç‰‡è‡ªèº« CTR å˜åŒ–çš„å½±å“ã€‚\n- **æµé‡ç»“æ„**: æµé‡åˆ†é…å˜åŒ–å¸¦æ¥çš„å½±å“ã€‚\n- **æ–°å¡çº¢åˆ©**: æ–°ä¸Šæ¶å¡ç‰‡å¸¦æ¥çš„å¢é‡ã€‚")
        with c_t: 
            st.success(f"**ğŸ¤– æ™ºèƒ½è¯Šæ–­**ï¼š\n\n{conclusion}")

        st.divider()
        st.subheader("ğŸ” é‡æ•ˆæ°”æ³¡å›¾ (å­˜é‡å¡ç‰‡)")
        valid_scatter = df_m[df_m['IsCommon']].copy()
        if not valid_scatter.empty:
            valid_scatter['ExpChg'] = (valid_scatter['exposure_uv_B'] - valid_scatter['exposure_uv_A']) / (valid_scatter['exposure_uv_A'] + 1)
            valid_scatter['CTRChg'] = valid_scatter['CTRB'] - valid_scatter['CTRA']
            valid_scatter['label'] = valid_scatter['card_id']
            fig = px.scatter(valid_scatter, x="ExpChg", y="CTRChg", hover_name="label", size="exposure_uv_B", color="Contrib", color_continuous_scale="RdYlGn", title="æ›å…‰å˜åŒ– vs CTRå˜åŒ– (å³ä¸Šè§’=é‡ä»·é½å‡)")
            fig.add_hline(y=0, line_dash="dash"); fig.add_vline(x=0, line_dash="dash")
            fig.update_xaxes(tickformat=".0%"); fig.update_yaxes(tickformat=".2%")
            st.plotly_chart(fig, use_container_width=True)

        st.subheader("ğŸ† è´¡çŒ®åº¦æ’è¡Œæ¦œ (Contribution)")
        def get_stat_label(r):
            if r['IsNew']: return 'ğŸŸ¢ New'
            if r['IsLost']: return 'ğŸ”´ Lost'
            return 'ğŸ”µ Common'
        df_m['Status'] = df_m.apply(get_stat_label, axis=1)
        
        c_top, c_bot = st.columns(2)
        with c_top:
            st.markdown("**ğŸš€ æ­£å‘æ‹‰åŠ¨ Top 5**")
            st.dataframe(df_m.sort_values('Contrib', ascending=False).head(5)[[cols[0], 'Status', 'Contrib', 'CTRB']].style.format({'Contrib':'+{:.2%}', 'CTRB':'{:.2%}'}), hide_index=True)
        with c_bot:
            st.markdown("**ğŸ“‰ è´Ÿå‘æ‹–ç´¯ Top 5**")
            st.dataframe(df_m.sort_values('Contrib', ascending=True).head(5)[[cols[0], 'Status', 'Contrib', 'CTRB']].style.format({'Contrib':'{:.2%}', 'CTRB':'{:.2%}'}), hide_index=True)

        st.divider()
        st.subheader("ğŸ“‹ è¯¦ç»†æ•°æ®è¡¨")
        show_cols = ['Status'] + cols + ['Contrib', 'exposure_uv_A', 'exposure_uv_B', 'CTRA', 'CTRB']
        st.dataframe(df_m[show_cols].sort_values('Contrib', ascending=False).style.format({'Contrib':'{:.2%}', 'CTRA':'{:.2%}', 'CTRB':'{:.2%}', 'exposure_uv_A':'{:.0f}', 'exposure_uv_B':'{:.0f}'}).background_gradient(subset=['Contrib'], cmap='RdYlGn', vmin=-0.005, vmax=0.005), use_container_width=True)
        
        st.divider()
        c_e1, c_e2 = st.columns(2)
        word_file = generate_word_report(f"å½’å› æˆ˜æŠ¥-{manual_country}", {"CTRå˜åŒ–": f"{ctra:.2%}->{ctrb:.2%}"}, conclusion, {"è´¡çŒ®æ¦œ": df_m.head(5)})
        excel_file = generate_excel({"å½’å› æ˜ç»†": df_m})
        with c_e1: st.download_button("ğŸ“„ Word", word_file, f"Report_{la}.docx", key=f"bw_{la}")
        with c_e2: st.download_button("ğŸ“Š Excel", excel_file, f"Data_{la}.xlsx", key=f"be_{la}")

def show_comparison(df1, df2):
    show_comparison_logic(df1, df2)

# --- ä¸»é€»è¾‘ ---
df_a_raw = None
if file_a: df_a_raw = process_data(file_a, sheet_name_a, visible_only=read_visible_only)
df_b_raw = None
if file_b: df_b_raw = process_data(file_b, sheet_name_b, visible_only=read_visible_only)

# å…¨å±€æ¸…æ´—
df_a = filter_dataframe(df_a_raw, min_exp_noise)
df_b = filter_dataframe(df_b_raw, min_exp_noise)

if df_a is not None:
    if df_b is not None:
        mode = st.radio("ğŸ‘‡ æ¨¡å¼", ["ğŸ“„ å•æ–‡ä»¶åˆ†æ", "âš”ï¸ åŒè¡¨å¯¹æ¯”"], horizontal=True)
        st.divider()
        if mode == "ğŸ“„ å•æ–‡ä»¶åˆ†æ":
            t1, t2 = st.tabs(["è¡¨æ ¼ A", "è¡¨æ ¼ B"])
            with t1: show_single_analysis(df_a, "è¡¨æ ¼ A")
            with t2: show_single_analysis(df_b, "è¡¨æ ¼ B", is_secondary=True)
        else:
            show_comparison(df_a, df_b)
    else:
        show_single_analysis(df_a, "è¡¨æ ¼ A")
else:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¸Šä¼  Excel æ–‡ä»¶ã€‚")

if GLOBAL_DATA_CONTEXT != "æš‚æ— æ•°æ®ã€‚":
    init_ai_sidebar(GLOBAL_DATA_CONTEXT)
